{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e954ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import trange   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e37f34",
   "metadata": {},
   "source": [
    "The MNIST dataset is very popular machine learning dataset, consisting of 70000 grayscale images of handwritten digits, of dimensions 28x28. We'll be using it as our example for this section of the tutorial, with the goal being to predict which the digit is in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70787956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0439dc0",
   "metadata": {},
   "source": [
    "Let's take a look at how the data is organized. Heads up, the code below has been modified according to newest upgrades. See chat history here: https://chat.openai.com/share/8a411cba-bdc9-4aca-9180-c37d86ecd008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c62b80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image data: (55002, 784)\n",
      "Validation image data: (4998, 784)\n",
      "Testing image data: (10000, 784)\n",
      "28 x 28 = 784\n",
      "\n",
      "Test Labels: (10000,)\n",
      "Label distribution: [(0, 980), (1, 1135), (2, 1032), (3, 1010), (4, 982), (5, 892), (6, 958), (7, 1028), (8, 974), (9, 1009)]\n",
      "\n",
      "Train image 1 is labelled as 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a3cef6c730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the image data\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "validation_split = 0.0833  # Approximately 5000 samples for validation\n",
    "num_validation_samples = int(validation_split * len(x_train))\n",
    "\n",
    "x_val = x_train[:num_validation_samples]\n",
    "y_val = y_train[:num_validation_samples]\n",
    "\n",
    "x_train = x_train[num_validation_samples:]\n",
    "y_train = y_train[num_validation_samples:]\n",
    "\n",
    "# Dataset statistics\n",
    "print('Training image data: {0}'.format(x_train.shape))\n",
    "print('Validation image data: {0}'.format(x_val.shape))\n",
    "print('Testing image data: {0}'.format(x_test.shape))\n",
    "print('28 x 28 = {0}'.format(28 * 28))\n",
    "\n",
    "print('\\nTest Labels: {0}'.format(y_test.shape))\n",
    "labels, num_labels = np.unique(y_test, return_counts=True)\n",
    "print('Label distribution: {0}'.format(list(zip(labels, num_labels))))\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled as {0}'.format(y_train[1]))\n",
    "image = x_train[1].reshape(28, 28)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02340761",
   "metadata": {},
   "source": [
    "Logistic Regression Model: Define the graph input: this is where we feed in our training images into the model. Since MNIST digits are pretty small and the model we're using is very simple, we'll feed them in as flat vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df202",
   "metadata": {},
   "source": [
    "Old code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80bf1d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define input placeholder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m(tf\u001b[38;5;241m.\u001b[39mfloat32, [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m784\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Define input placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01353bd",
   "metadata": {},
   "source": [
    "New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c57fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input placeholder\n",
    "x = tf.keras.Input(shape=(784,), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c06bd5",
   "metadata": {},
   "source": [
    "To get our predicted probabilities of each digit, let's first start with the probability of a digit being a 3 like the image above. For our simple model, we start by applying a linear transformation. That is, we multiply each value of the input vector by a weight, sum them all together, and then add a bias. In equation form:\n",
    "\n",
    "ùë¶3=‚àëùëñùë§ùëñ,3ùë•ùëñ+ùëè3\n",
    " \n",
    "The magnitude of this result  ùë¶3\n",
    " , we'll take as being correlated to our belief in how likely we think the input digit was a 3. The higher the value of  ùë¶3\n",
    " , the more likely we think the input image  ùë•\n",
    "  was a 3 (ie, we'd hope we'd get a relatively large value for  ùë¶3\n",
    "  for the above image). Remember though, our original goal was to identify all 10 digits, so we also have:\n",
    "\n",
    "ùë¶0=ùë¶9=‚àëùëñùë§ùëñ,0ùë•ùëñ+ùëè0\n",
    "...\n",
    "y9=‚àëùëñùë§ùëñ,9ùë•ùëñ+ùëè9\n",
    " \n",
    "We can express this in matrix form as:\n",
    "\n",
    "ùë¶=ùëäùë•+ùëè\n",
    " \n",
    "To put this into our graph in TensorFlow, we need to define some Variables to hold the weights and biases:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60add07",
   "metadata": {},
   "source": [
    "old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c2c7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(784, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(10,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "# Define linear transformation\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb901471",
   "metadata": {},
   "source": [
    "new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0305523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\"W\",\n",
    "                                 shape=[input_shape[-1], self.num_outputs],\n",
    "                                 initializer=tf.zeros_initializer())\n",
    "        self.b = self.add_weight(\"b\",\n",
    "                                 shape=[self.num_outputs],\n",
    "                                 initializer=tf.zeros_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.W) + self.b\n",
    "\n",
    "x = tf.keras.Input(shape=(784,))\n",
    "linear_layer = LinearLayer(num_outputs=10)\n",
    "y = linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f2c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240dd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4523e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350511c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8774cfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c45109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
