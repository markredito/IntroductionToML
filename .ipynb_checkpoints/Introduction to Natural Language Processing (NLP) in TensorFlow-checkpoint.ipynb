{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7156ab0",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing (NLP) in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3debc9e",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506ac12",
   "metadata": {},
   "source": [
    "Word embeddings, or word vectors, provide a way of mapping words from a vocabulary into a low-dimensional space, where words with similar meanings are close together. Let's play around with a set of pre-trained word vectors, to get used to their properties. There exist many sets of pretrained word embeddings; here, we use ConceptNet Numberbatch, which provides a relatively small download in an easy-to-work-with format (h5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ddd485",
   "metadata": {},
   "source": [
    "To read an `h5` file, we'll need to use the `h5py` package. Below, we use the package to open the `mini.h5` file we just downloaded. We extract from the file a list of utf-8-encoded words, as well as their $300$-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b535d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\mark\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\mark\\anaconda3\\lib\\site-packages (from h5py) (1.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4bbe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words dimensions: 362891\n",
      "all_embeddings dimensions: (362891, 300)\n",
      "/c/de/aufmachung\n"
     ]
    }
   ],
   "source": [
    "# Load the file and pull out words and embeddings\n",
    "import h5py\n",
    "\n",
    "with h5py.File('datasets/mini.h5', 'r') as f:\n",
    "    all_words = [word.decode('utf-8') for word in f['mat']['axis1'][:]]\n",
    "    all_embeddings = f['mat']['block0_values'][:]\n",
    "    \n",
    "print(\"all_words dimensions: {0}\".format(len(all_words)))\n",
    "print(\"all_embeddings dimensions: {0}\".format(all_embeddings.shape))\n",
    "\n",
    "print(all_words[1337])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b74030",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The code loads the `mini.h5` dataset using the `h5py` package.\n",
    "- It extracts all words and their corresponding embeddings from the dataset.\n",
    "- all_words is a list of words encoded in utf-8, which are then decoded.\n",
    "- all_embeddings is a matrix where each row corresponds to the embedding of a word.\n",
    "- The dimensions of both the list and matrix are printed to get a sense of their sizes.\n",
    "- It prints the word at index 1337 as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f1729",
   "metadata": {},
   "source": [
    "Now, `all_words` is a list of $V$ strings (what we call our *vocabulary*), and `all_embeddings` is a $V \\times 300$ matrix. The strings are of the form `/c/language_code/word`â€”for example, `/c/en/cat` and `/c/es/gato`.\n",
    "\n",
    "We are interested only in the English words. We use Python list comprehensions to pull out the indices of the English words, then extract just the English words (stripping the six-character `/c/en/` prefix) and their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400bad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words dimensions: 150875\n",
      "all_embeddings dimensions: (150875, 300)\n",
      "activated_carbon\n"
     ]
    }
   ],
   "source": [
    "# Restrict our vocabulary to just the English words\n",
    "english_words = [word[6:] for word in all_words if word.startswith('/c/en/')]\n",
    "english_word_indices = [i for i, word in enumerate(all_words) if word.startswith('/c/en/')]\n",
    "english_embeddings = all_embeddings[english_word_indices]\n",
    "\n",
    "print(\"all_words dimensions: {0}\".format(len(english_words)))\n",
    "print(\"all_embeddings dimensions: {0}\".format(english_embeddings.shape))\n",
    "\n",
    "print(english_words[1337])\n",
    "\n",
    "#To focus on semantics (meaning), it's beneficial to normalize our vectors, \n",
    "#which means adjusting them so that they all have a length of 1. \n",
    "#After normalization, all word vectors will lie on a unit circle, and \n",
    "#the dot product of two vectors will be proportional to the cosine of the angle between them, \n",
    "#giving a measure of their similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165542d",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- This cell filters out only the English words and their embeddings.\n",
    "- Words starting with `/c/en/` are identified as English. The first 6 characters `/c/en/` are stripped to retain only the word.\n",
    "- Indices of English words are stored in `english_word_indices`.\n",
    "- Using these indices, the corresponding embeddings are extracted to `english_embeddings`.\n",
    "- Dimensions and an example word are printed for verification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291dec65",
   "metadata": {},
   "source": [
    "The magnitude of a word vector is less important than its direction; the magnitude can be thought of as representing frequency of use, independent of the semantics of the word. \n",
    "Here, we will be interested in semantics, so we *normalize* our vectors, dividing each by its length. \n",
    "The result is that all of our word vectors are length 1, and as such, lie on a unit circle. \n",
    "The dot product of two vectors is proportional to the cosine of the angle between them, and provides a measure of similarity (the bigger the cosine, the smaller the angle).\n",
    "\n",
    "<img src=\"Figures/cosine_similarity.png\" alt=\"cosine\" style=\"width: 500px;\"/>\n",
    "<center>Figure adapted from *[Mastering Machine Learning with Spark 2.x](https://www.safaribooksonline.com/library/view/mastering-machine-learning/9781785283451/ba8bef27-953e-42a4-8180-cea152af8118.xhtml)*</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74aa5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "norms = np.linalg.norm(english_embeddings, axis=1)\n",
    "normalized_embeddings = english_embeddings.astype('float32') / norms.astype('float32').reshape([-1, 1])\n",
    "\n",
    "#The cell normalizes the English word embeddings.\n",
    "#It computes the norms (lengths) of the embeddings using np.linalg.norm.\n",
    "#Each embedding is then divided by its norm to normalize it.\n",
    "#The result, normalized_embeddings, contains vectors of length 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4eb310",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The cell normalizes the English word embeddings.\n",
    "- It computes the norms (lengths) of the embeddings using `np.linalg.norm`.\n",
    "- Each embedding is then divided by its norm to normalize it.\n",
    "- The result, `normalized_embeddings`, contains vectors of length 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb27520",
   "metadata": {},
   "source": [
    "The np.linalg.norm function is used to compute the Euclidean norm (or length) of each word vector in english_embeddings. The axis=1 argument ensures that the norm is computed for each row (word vector) individually. The result, norms, is an array of lengths for each word vector.\n",
    "\n",
    "Each word vector in english_embeddings is divided by its corresponding norm to normalize it. The reshape([-1, 1]) part is used to ensure that the division is carried out element-wise for each row. The astype('float32') ensures that the division is done using floating-point arithmetic.\n",
    "\n",
    "The result is stored in normalized_embeddings, which contains the normalized word vectors, each of length 1.\n",
    "After this step, we'll have word vectors that are standardized in length, allowing us to focus on their direction (or angle) when measuring similarity between words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0d2b0",
   "metadata": {},
   "source": [
    "## Creating a Dictionary for Word Lookup\n",
    "\n",
    "This dictionary will map words to their indices in the word embeddings matrix. Such a dictionary is useful when you want to quickly retrieve the embedding of a specific word without searching through the entire list.\n",
    "\n",
    "By constructing this dictionary, the process of finding the vector representation for any given word becomes efficient. Instead of linearly searching through the list of words, the dictionary provides constant-time (O(1)) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d73b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {word: i for i, word in enumerate(english_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e24e02d",
   "metadata": {},
   "source": [
    "- Code above constructs a dictionary named index using a dictionary comprehension.\n",
    "- The enumerate function is used to loop over english_words and generate both the word and its corresponding index.\n",
    "- Each word (word) is used as a key in the dictionary, and its index (i) is used as the associated value.\n",
    "- The resulting dictionary allows for efficient lookups: given a word, you can quickly find its index in the english_words list (and, by extension, its corresponding embedding in the normalized_embeddings matrix).\n",
    "\n",
    "This dictionary will be invaluable when you want to quickly retrieve the embedding of a specific word or perform operations based on word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd82da8",
   "metadata": {},
   "source": [
    "*The dot product is a mathematical operation that takes two equal-length sequences of numbers and returns a single number. In the context of word embeddings, the dot product between two normalized word vectors measures the cosine of the angle between them. Since the vectors are normalized (having a magnitude of 1), this dot product directly gives the cosine similarity, which is a measure of how similar the two vectors (and thus the words they represent) are. A value close to 1 indicates high similarity, while a value close to -1 indicates high dissimilarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5193c5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\tcat\t 1.0\n",
      "cat\tfeline\t 0.8199548\n",
      "cat\tdog\t 0.590724\n",
      "cat\tmoo\t 0.0039538294\n",
      "cat\tfreeze\t -0.030225191\n"
     ]
    }
   ],
   "source": [
    "def similarity_score(w1, w2):\n",
    "    score = np.dot(normalized_embeddings[index[w1], :], normalized_embeddings[index[w2], :])\n",
    "    return score\n",
    "\n",
    "# A word is as similar with itself as possible:\n",
    "print('cat\\tcat\\t', similarity_score('cat', 'cat'))\n",
    "\n",
    "# Closely related words still get high scores:\n",
    "print('cat\\tfeline\\t', similarity_score('cat', 'feline'))\n",
    "print('cat\\tdog\\t', similarity_score('cat', 'dog'))\n",
    "\n",
    "# Unrelated words, not so much:\n",
    "print('cat\\tmoo\\t', similarity_score('cat', 'moo'))\n",
    "print('cat\\tfreeze\\t', similarity_score('cat', 'freeze'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc588d",
   "metadata": {},
   "source": [
    "# Function Definition:\n",
    "- The similarity_score function calculates the cosine similarity between two words (w1 and w2) using their normalized embeddings.\n",
    "- It retrieves the embeddings of the words from the normalized_embeddings matrix using the indices provided by the index dictionary.\n",
    "- The np.dot function computes the dot product of the two embeddings, which, since they're normalized, directly gives the cosine similarity.\n",
    "\n",
    "# Testing the Function:\n",
    "The function is then tested on various word pairs:\n",
    "- A word with itself (cat vs. cat): As expected, the similarity score is 1 because a word is maximally similar to itself.\n",
    "- Semantically related words (cat vs. feline and cat vs. dog): The scores are expected to be high as the words are closely related.\n",
    "- Unrelated words (cat vs. moo and cat vs. freeze): The scores should be considerably lower, reflecting the lack of semantic relation between the pairs.\n",
    "\n",
    "This function provides a convenient way to measure how semantically similar two words are based on their embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2bf34",
   "metadata": {},
   "source": [
    "# Finding Most Similar Words\n",
    "\n",
    "Using the cosine similarity measure (or dot product for normalized vectors), it's possible to determine which words in the vocabulary are most similar to a specific word. This is typically achieved by computing the similarity score between the given word and every other word in the vocabulary and then ranking the words based on these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063a0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_to_vector(v, n):\n",
    "    all_scores = np.dot(normalized_embeddings, v)\n",
    "    best_words = map(lambda i: english_words[i], reversed(np.argsort(all_scores)))\n",
    "    return [next(best_words) for _ in range(n)]\n",
    "\n",
    "def most_similar(w, n):\n",
    "    return closest_to_vector(normalized_embeddings[index[w], :], n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59a09d",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**closest_to_vector(v, n) Function:**\n",
    "\n",
    "- This function finds the n words that have the most similar embeddings to a given vector v.\n",
    "- It computes the dot product (or cosine similarity since vectors are normalized) between the given vector v and all the word embeddings in normalized_embeddings using np.dot.\n",
    "- The scores are then sorted in descending order using np.argsort (which returns indices in ascending order, hence the use of reversed).\n",
    "- Using the sorted indices, the corresponding words are fetched from the english_words list.\n",
    "- The function finally returns the top n words that are most similar to the input vector v.\n",
    "\n",
    "**most_similar(w, n) Function:**\n",
    "\n",
    "- This function is a more user-friendly interface that finds the n words most similar to a given word w.\n",
    "- It retrieves the normalized embedding of the word w using the index dictionary.\n",
    "- It then calls the closest_to_vector function to get the n most similar words.\n",
    "\n",
    "With these functions, you can easily find which words in the vocabulary are most similar to any given word, based on their vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef099aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'humane_society', 'kitten', 'feline', 'colocolo', 'cats', 'kitty', 'maine_coon', 'housecat', 'sharp_teeth']\n",
      "['dog', 'dogs', 'wire_haired_dachshund', 'doggy_paddle', 'lhasa_apso', 'good_friend', 'puppy_dog', 'bichon_frise', 'woof_woof', 'golden_retrievers']\n",
      "['duke', 'dukes', 'duchess', 'duchesses', 'ducal', 'dukedom', 'duchy', 'voivode', 'princes', 'prince']\n"
     ]
    }
   ],
   "source": [
    "#finding most similar words for specific inputs\n",
    "print(most_similar('cat', 10))\n",
    "print(most_similar('dog', 10))\n",
    "print(most_similar('duke', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8ad50",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The function `most_similar` is invoked three times with different input words: 'cat', 'dog', and 'duke'.\n",
    "- For each word, the function returns a list of the 10 words that are most similar to the input word based on their embeddings.\n",
    "- The results are printed to provide insight into which words in the vocabulary are deemed most similar to the input words.\n",
    "\n",
    "By examining the output, you can gauge the effectiveness of the embeddings in capturing semantic similarities between words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275c63a",
   "metadata": {},
   "source": [
    "# Solving Analogies with Word Embeddings\n",
    "The method involves using vector arithmetic to find words \"nearby\" vectors that we construct ourselves.\n",
    "\n",
    "**Explanation:**\n",
    "Word embeddings have a fascinating property where semantic relationships between words can often be captured using vector arithmetic. For instance, the analogy \"man : brother :: woman : ?\" can be expressed as the equation: \"brother - man + woman\". In words, this means: start with the meaning of \"brother\", subtract the meaning of \"man\", and add the meaning of \"woman\". This vector arithmetic often results in a vector close to the word that solves the analogy, in this case, potentially \"sister\".\n",
    "\n",
    "By using the closest_to_vector function, we can determine which words in the embedding space are closest to this new vector, and thus, solve the analogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1982b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sister']\n",
      "['wife']\n",
      "['paris']\n"
     ]
    }
   ],
   "source": [
    "def solve_analogy(a1, b1, a2):\n",
    "    b2 = normalized_embeddings[index[b1], :] - normalized_embeddings[index[a1], :] + normalized_embeddings[index[a2], :]\n",
    "    return closest_to_vector(b2, 1)\n",
    "\n",
    "print(solve_analogy(\"man\", \"brother\", \"woman\"))\n",
    "print(solve_analogy(\"man\", \"husband\", \"woman\"))\n",
    "print(solve_analogy(\"spain\", \"madrid\", \"france\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107214c5",
   "metadata": {},
   "source": [
    "**Function Definition:**\n",
    "- The function `solve_analogy` is defined to solve analogies of the form a1:b1::a2:?.\n",
    "- The logic involves using vector arithmetic:`b2 = embedding(b1) - embedding(a1) + embedding(a2)`. This computes the vector that represents the unknown word in the analogy.\n",
    "- The function then calls closest_to_vector with the computed vector `*b2*` to find the word in the vocabulary that is closest to this computed vector. This word is the solution to the analogy.\n",
    "\n",
    "**Testing the Function:**\n",
    "The function is tested on three different analogies:\n",
    "- `man:brother::woman:?`\n",
    "- `man:husband::woman:?`\n",
    "- `spain:madrid::france:?`\n",
    "The results are printed to see which words the model predicts as the solutions to these analogies.\n",
    "\n",
    "By examining the output, you can gauge the ability of the word embeddings to capture semantic relationships and solve word analogies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b38505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knife']\n",
      "['america']\n",
      "['shelf']\n"
     ]
    }
   ],
   "source": [
    "#testing analogies\n",
    "def solve_analogy(a1, b1, a2):\n",
    "    b2 = normalized_embeddings[index[b1], :] - normalized_embeddings[index[a1], :] + normalized_embeddings[index[a2], :]\n",
    "    return closest_to_vector(b2, 1)\n",
    "\n",
    "print(solve_analogy(\"pen\", \"paper\", \"knife\"))\n",
    "print(solve_analogy(\"philippines\", \"manila\", \"america\"))\n",
    "print(solve_analogy(\"bottle\", \"liquid\", \"shelf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2045e",
   "metadata": {},
   "source": [
    "*above - dissapointing result*\n",
    "\n",
    "**Reasons for the Unexpected Results:**\n",
    "- **Embedding Quality:** Not all word embeddings capture every semantic relationship equally well. The quality and ability of embeddings to solve analogies depend on the data they were trained on and the method used.\n",
    "\n",
    "- **Limitations of Vector Arithmetic for Analogies:** While vector arithmetic can capture many semantic relationships, it isn't perfect and doesn't always work for every analogy.\n",
    "\n",
    "- **Vocabulary and Training Data:** The embeddings in the mini.h5 file might be from a limited vocabulary or might not have been trained on a diverse enough dataset to capture all types of relationships.\n",
    "\n",
    "- **Nature of Analogies:** Analogies are complex and can be interpreted in multiple ways. The relationships in your examples are not as commonly used in analogy datasets as the classic \"man:king::woman:queen\" type.\n",
    "\n",
    "Potential Solutions:\n",
    "- Different Embeddings\n",
    "- Fine tuning\n",
    "- Explicit Relationship Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c09da",
   "metadata": {},
   "source": [
    "# Using word embeddings in deep models\n",
    "\n",
    "**Continuous Space for Words:** Word embeddings enable us to perceive words as existing in a continuous, Euclidean space. This representation allows words to be treated similarly to continuous numerical data, which facilitates the use of various machine learning techniques that are tailored for such data.\n",
    "\n",
    "**Application - Sentiment Analysis:** The notebook proposes an experiment involving sentiment analysis on a collection of movie reviews. Sentiment analysis aims to determine the mood or sentiment of a piece of text, such as identifying whether a movie review is positive or negative.\n",
    "\n",
    "**Using Word Embeddings in Models:** To perform sentiment analysis, word embeddings can be employed as features in machine learning models, like logistic regression or neural networks. The embeddings provide a dense representation of words, which can help models capture semantic nuances in the text.\n",
    "\n",
    "The subsequent cells will delve deeper into the process of sentiment analysis and demonstrate how to utilize word embeddings in building a sentiment analysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ff6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing movie reviews\n",
    "import string\n",
    "remove_punct=str.maketrans('','',string.punctuation)\n",
    "\n",
    "# This function converts a line of our data file into\n",
    "# a tuple (x, y), where x is 300-dimensional representation\n",
    "# of the words in a review, and y is its label.\n",
    "def convert_line_to_example(line):\n",
    "    # Pull out the first character: that's our label (0 or 1)\n",
    "    y = int(line[0])\n",
    "    \n",
    "    # Split the line into words using Python's split() function\n",
    "    words = line[2:].translate(remove_punct).lower().split()\n",
    "    \n",
    "    # Look up the embeddings of each word, ignoring words not\n",
    "    # in our pretrained vocabulary.\n",
    "    embeddings = [normalized_embeddings[index[w]] for w in words\n",
    "                  if w in index]\n",
    "    \n",
    "    # Take the mean of the embeddings\n",
    "    x = np.mean(np.vstack(embeddings), axis=0)\n",
    "    return {'x': x, 'y': y}\n",
    "\n",
    "# Apply the function to each line in the file.\n",
    "with open(\"movie-simple.txt\", \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "    dataset = [convert_line_to_example(l) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6c84f",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Removing Punctuation:**\n",
    "- The `string.punctuation` variable contains all punctuation characters. Using `str.maketrans()`, a translation table is created that will be used to remove all punctuation from a string.\n",
    "\n",
    "**Function - `convert_line_to_example(line)`:**\n",
    "- This function processes a line from the dataset.\n",
    "- **Label Extraction**: The first character of the line is expected to be the label (0 or 1), indicating whether the review is negative or positive, respectively.\n",
    "- **Text Processing**: The function then processes the review text:\n",
    "    Punctuation is removed using the translation table created earlier.\n",
    "    The text is converted to lowercase.\n",
    "    The review is split into individual words.\n",
    "- The output of the function will be a tuple `(x, y)`, where `x` represents the processed words of the review, and `y` is the label.\n",
    "\n",
    "This function is a crucial step in preparing the data for training. It ensures that the input text is cleaned and converted into a format amenable for training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87ce1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n",
    "# checks the length (or number of entries) of the dataset variable. \n",
    "#This is a common practice to understand the size of the dataset you're working with, \n",
    "#especially before processing or training.\n",
    "#The output will give us the total number of movie reviews in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b522",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "- **Shuffling the Dataset:** Before splitting the data into training and test sets, it's a common practice to shuffle the dataset. This ensures that the training and test data are random samples and do not contain any inherent order that might affect the model's performance.\n",
    "\n",
    "- **Train/Test Split:** The dataset will be divided into two parts:\n",
    "Training Set: Used for training the model.\n",
    "Test Set: Used for evaluating the model's performance on unseen data.\n",
    "\n",
    "Typically, a common ratio like 75%-25% or 80%-20% is used for the train-test split. Here, the notebook mentions using three-quarters of the dataset for training and a quarter for testing.\n",
    "\n",
    "- **Whole Number of Batches:** The cell also notes the intention to ensure that the training set size is a multiple of the batch size. This simplifies the batching process during training.\n",
    "\n",
    "The subsequent code cells will demonstrate how to shuffle the dataset and perform the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b253a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset)\n",
    "\n",
    "batch_size = 100\n",
    "total_batches = len(dataset) // batch_size\n",
    "train_batches = 3*total_batches // 4 \n",
    "train, test = dataset[:train_batches*batch_size], dataset[train_batches*batch_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4dce0",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Data Shuffling:**\n",
    "- The `random.shuffle()` function is utilized to shuffle the entries of the dataset in place. This randomizes the order of the movie reviews.\n",
    "\n",
    "**Setting Batch Size:**\n",
    "- A `batch_size` of 100 is defined, indicating that the model will be trained using batches of 100 reviews at a time.\n",
    "\n",
    "**Computing Total Batches:**\n",
    "- The total number of batches in the dataset is computed using integer division. This ensures that the total number of reviews considered is a multiple of the batch size.\n",
    "\n",
    "**Splitting into Training and Test Sets:**\n",
    "- 75% of the batches (train_batches) are allocated for training, and the remaining 25% are for testing.\n",
    "- The dataset is then split based on these batch counts to form the `train` and `test` sets.\n",
    "\n",
    "By following this approach, the notebook ensures that both the training and test data are multiple of the batch size, which will be convenient for batch processing during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d12c7",
   "metadata": {},
   "source": [
    "# Building the MLP with TensorFlow\n",
    "**Placeholders for X and y:** Before building the model, placeholders will be defined for the input data X (the movie reviews) and the labels y. In TensorFlow, placeholders are symbolic variables that allow us to feed in actual data at runtime.\n",
    "\n",
    "**MLP Architecture:** The subsequent cells will likely detail the architecture of the MLP, including the number of layers, neurons in each layer, activation functions, and the methods used for optimization and loss computation.\n",
    "\n",
    "The following code cells will demonstrate how to set up this TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81a21f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,141\n",
      "Trainable params: 32,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Revised code for TensorFlow 2.x using Keras API\n",
    "\n",
    "# Define the model using Keras Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(300,)),  # Input layer\n",
    "    tf.keras.layers.Dense(100, activation='relu'),  # First hidden layer\n",
    "    tf.keras.layers.Dense(20, activation='relu'),  # Second hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and accuracy metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ecf1a1",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Importing TensorFlow:** The TensorFlow library is imported, which provides the necessary tools and functions to define, train, and evaluate neural network models.\n",
    "\n",
    "**Input Placeholders:**\n",
    "`tf.keras.layers.Input(shape=(300,))`\n",
    "The concept of placeholders (tf.placeholder) is not used in TensorFlow 2.x since there's no static computational graph. Instead, you'd define models and pass data directly to them.\n",
    "\n",
    "**MLP Architecture:**\n",
    "- `tf.keras.layers.Dense(100, activation='relu')`The first hidden layer with 100 neurons and the ReLU activation function. It takes the input X and transforms it.\n",
    "- `tf.keras.layers.Dense(20, activation='relu')` The second hidden layer with 20 neurons and the ReLU activation function. It takes the output of h1 as its input.\n",
    "- `tf.keras.layers.Dense(1, activation='sigmoid')` The output layer. It produces the raw scores for each review. It has 1 neuron since this is a binary classification task.\n",
    "\n",
    "**Loss and Metrics:**\n",
    "\n",
    "**loss:** Computes the binary cross-entropy loss between the predicted logits and the true labels.\n",
    "**accuracy:** Computes the classification accuracy. It first rounds the predicted probabilities to get binary predictions and then compares them to the true labels.\n",
    "\n",
    "This setup provides a complete three-layer MLP architecture for sentiment analysis, along with the necessary components to train and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b09a5",
   "metadata": {},
   "source": [
    "# Training the MLP\n",
    "\n",
    "**Session Initiation:** For TensorFlow 1.x, the typical approach to executing the computational graph involves starting a TensorFlow session. However, please note that in TensorFlow 2.x (as discussed previously), the concept of sessions and placeholders has been removed in favor of eager execution.\n",
    "\n",
    "**Training Epochs:** The notebook mentions that the model will be trained for 250 epochs. An epoch is one complete forward and backward pass of all the training examples.\n",
    "\n",
    "**Evaluation:** After training, the model's accuracy will be evaluated on the test data to determine its performance on unseen samples.\n",
    "\n",
    "The subsequent code cells will likely demonstrate the process of training the model for the specified number of epochs and then evaluating it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ed04c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 0.6865 - accuracy: 0.6090 - val_loss: 0.6703 - val_accuracy: 0.6926\n",
      "Epoch 2/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.6888 - val_loss: 0.6295 - val_accuracy: 0.7067\n",
      "Epoch 3/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.7154 - val_loss: 0.5636 - val_accuracy: 0.7703\n",
      "Epoch 4/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.8262 - val_loss: 0.4752 - val_accuracy: 0.8799\n",
      "Epoch 5/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8989 - val_loss: 0.3790 - val_accuracy: 0.9187\n",
      "Epoch 6/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.9131 - val_loss: 0.2963 - val_accuracy: 0.9435\n",
      "Epoch 7/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.9326 - val_loss: 0.2381 - val_accuracy: 0.9435\n",
      "Epoch 8/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.9353 - val_loss: 0.1974 - val_accuracy: 0.9505\n",
      "Epoch 9/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9424 - val_loss: 0.1751 - val_accuracy: 0.9505\n",
      "Epoch 10/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9495 - val_loss: 0.1537 - val_accuracy: 0.9576\n",
      "Epoch 11/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9530 - val_loss: 0.1467 - val_accuracy: 0.9576\n",
      "Epoch 12/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.9566 - val_loss: 0.1378 - val_accuracy: 0.9647\n",
      "Epoch 13/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9619 - val_loss: 0.1262 - val_accuracy: 0.9576\n",
      "Epoch 14/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9654 - val_loss: 0.1288 - val_accuracy: 0.9647\n",
      "Epoch 15/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9681 - val_loss: 0.1228 - val_accuracy: 0.9576\n",
      "Epoch 16/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9725 - val_loss: 0.1166 - val_accuracy: 0.9576\n",
      "Epoch 17/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9716 - val_loss: 0.1283 - val_accuracy: 0.9576\n",
      "Epoch 18/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9743 - val_loss: 0.1158 - val_accuracy: 0.9611\n",
      "Epoch 19/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9770 - val_loss: 0.1145 - val_accuracy: 0.9611\n",
      "Epoch 20/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9770 - val_loss: 0.1387 - val_accuracy: 0.9541\n",
      "Epoch 21/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9761 - val_loss: 0.1155 - val_accuracy: 0.9611\n",
      "Epoch 22/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9796 - val_loss: 0.1226 - val_accuracy: 0.9611\n",
      "Epoch 23/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9796 - val_loss: 0.1289 - val_accuracy: 0.9647\n",
      "Epoch 24/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9814 - val_loss: 0.1244 - val_accuracy: 0.9611\n",
      "Epoch 25/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9858 - val_loss: 0.1168 - val_accuracy: 0.9611\n",
      "Epoch 26/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9761 - val_loss: 0.1412 - val_accuracy: 0.9611\n",
      "Epoch 27/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9858 - val_loss: 0.1229 - val_accuracy: 0.9611\n",
      "Epoch 28/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9840 - val_loss: 0.1212 - val_accuracy: 0.9611\n",
      "Epoch 29/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9867 - val_loss: 0.1273 - val_accuracy: 0.9611\n",
      "Epoch 30/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9858 - val_loss: 0.1254 - val_accuracy: 0.9611\n",
      "Epoch 31/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9858 - val_loss: 0.1284 - val_accuracy: 0.9611\n",
      "Epoch 32/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9876 - val_loss: 0.1380 - val_accuracy: 0.9611\n",
      "Epoch 33/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9894 - val_loss: 0.1341 - val_accuracy: 0.9611\n",
      "Epoch 34/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9894 - val_loss: 0.1301 - val_accuracy: 0.9611\n",
      "Epoch 35/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9920 - val_loss: 0.1487 - val_accuracy: 0.9541\n",
      "Epoch 36/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.1392 - val_accuracy: 0.9611\n",
      "Epoch 37/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9911 - val_loss: 0.1389 - val_accuracy: 0.9611\n",
      "Epoch 38/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9947 - val_loss: 0.1481 - val_accuracy: 0.9611\n",
      "Epoch 39/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9938 - val_loss: 0.1449 - val_accuracy: 0.9611\n",
      "Epoch 40/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9956 - val_loss: 0.1464 - val_accuracy: 0.9611\n",
      "Epoch 41/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9947 - val_loss: 0.1573 - val_accuracy: 0.9541\n",
      "Epoch 42/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9947 - val_loss: 0.1514 - val_accuracy: 0.9611\n",
      "Epoch 43/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9947 - val_loss: 0.1462 - val_accuracy: 0.9647\n",
      "Epoch 44/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9947 - val_loss: 0.1563 - val_accuracy: 0.9611\n",
      "Epoch 45/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9965 - val_loss: 0.1584 - val_accuracy: 0.9611\n",
      "Epoch 46/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9965 - val_loss: 0.1693 - val_accuracy: 0.9576\n",
      "Epoch 47/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9956 - val_loss: 0.1670 - val_accuracy: 0.9576\n",
      "Epoch 48/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9965 - val_loss: 0.1547 - val_accuracy: 0.9611\n",
      "Epoch 49/250\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9982 - val_loss: 0.1682 - val_accuracy: 0.9576\n",
      "Epoch 50/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9982 - val_loss: 0.1731 - val_accuracy: 0.9541\n",
      "Epoch 51/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9982 - val_loss: 0.1743 - val_accuracy: 0.9541\n",
      "Epoch 52/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9982 - val_loss: 0.1754 - val_accuracy: 0.9576\n",
      "Epoch 53/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9973 - val_loss: 0.1671 - val_accuracy: 0.9647\n",
      "Epoch 54/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9973 - val_loss: 0.1996 - val_accuracy: 0.9505\n",
      "Epoch 55/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9973 - val_loss: 0.1711 - val_accuracy: 0.9611\n",
      "Epoch 56/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9973 - val_loss: 0.1764 - val_accuracy: 0.9611\n",
      "Epoch 57/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9973 - val_loss: 0.1928 - val_accuracy: 0.9541\n",
      "Epoch 58/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9982 - val_loss: 0.1861 - val_accuracy: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9982 - val_loss: 0.1851 - val_accuracy: 0.9576\n",
      "Epoch 60/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9991 - val_loss: 0.1917 - val_accuracy: 0.9541\n",
      "Epoch 61/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.1920 - val_accuracy: 0.9576\n",
      "Epoch 62/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 0.1963 - val_accuracy: 0.9541\n",
      "Epoch 63/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.2053 - val_accuracy: 0.9541\n",
      "Epoch 64/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.1982 - val_accuracy: 0.9541\n",
      "Epoch 65/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9991 - val_loss: 0.1941 - val_accuracy: 0.9576\n",
      "Epoch 66/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 0.2083 - val_accuracy: 0.9541\n",
      "Epoch 67/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 0.1966 - val_accuracy: 0.9611\n",
      "Epoch 68/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9541\n",
      "Epoch 69/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.2044 - val_accuracy: 0.9576\n",
      "Epoch 70/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9991 - val_loss: 0.2144 - val_accuracy: 0.9541\n",
      "Epoch 71/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 0.2061 - val_accuracy: 0.9576\n",
      "Epoch 72/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.2140 - val_accuracy: 0.9541\n",
      "Epoch 73/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.2079 - val_accuracy: 0.9576\n",
      "Epoch 74/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.2193 - val_accuracy: 0.9541\n",
      "Epoch 75/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.2203 - val_accuracy: 0.9541\n",
      "Epoch 76/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.2169 - val_accuracy: 0.9541\n",
      "Epoch 77/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.2172 - val_accuracy: 0.9541\n",
      "Epoch 78/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.2342 - val_accuracy: 0.9541\n",
      "Epoch 79/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 0.2153 - val_accuracy: 0.9576\n",
      "Epoch 80/250\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.2278 - val_accuracy: 0.9541\n",
      "Epoch 81/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.2288 - val_accuracy: 0.9541\n",
      "Epoch 82/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.2277 - val_accuracy: 0.9541\n",
      "Epoch 83/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.2322 - val_accuracy: 0.9541\n",
      "Epoch 84/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.2342 - val_accuracy: 0.9541\n",
      "Epoch 85/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.2362 - val_accuracy: 0.9541\n",
      "Epoch 86/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.2302 - val_accuracy: 0.9576\n",
      "Epoch 87/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.2315 - val_accuracy: 0.9576\n",
      "Epoch 88/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.2350 - val_accuracy: 0.9576\n",
      "Epoch 89/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.2441 - val_accuracy: 0.9541\n",
      "Epoch 90/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.2282 - val_accuracy: 0.9611\n",
      "Epoch 91/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.2456 - val_accuracy: 0.9541\n",
      "Epoch 92/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.2462 - val_accuracy: 0.9541\n",
      "Epoch 93/250\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.2370 - val_accuracy: 0.9576\n",
      "Epoch 94/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.2406 - val_accuracy: 0.9576\n",
      "Epoch 95/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.2648 - val_accuracy: 0.9470\n",
      "Epoch 96/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.2384 - val_accuracy: 0.9576\n",
      "Epoch 97/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.2483 - val_accuracy: 0.9541\n",
      "Epoch 98/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.2465 - val_accuracy: 0.9541\n",
      "Epoch 99/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2554 - val_accuracy: 0.9541\n",
      "Epoch 100/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.2458 - val_accuracy: 0.9541\n",
      "Epoch 101/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.2582 - val_accuracy: 0.9541\n",
      "Epoch 102/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2504 - val_accuracy: 0.9541\n",
      "Epoch 103/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.2610 - val_accuracy: 0.9541\n",
      "Epoch 104/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.2529 - val_accuracy: 0.9541\n",
      "Epoch 105/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.2556 - val_accuracy: 0.9541\n",
      "Epoch 106/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.2563 - val_accuracy: 0.9576\n",
      "Epoch 107/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.2659 - val_accuracy: 0.9541\n",
      "Epoch 108/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2563 - val_accuracy: 0.9576\n",
      "Epoch 109/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2638 - val_accuracy: 0.9541\n",
      "Epoch 110/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.2588 - val_accuracy: 0.9576\n",
      "Epoch 111/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2679 - val_accuracy: 0.9541\n",
      "Epoch 112/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.2551 - val_accuracy: 0.9541\n",
      "Epoch 113/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.2675 - val_accuracy: 0.9541\n",
      "Epoch 114/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.2663 - val_accuracy: 0.9576\n",
      "Epoch 115/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.2678 - val_accuracy: 0.9541\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.2660 - val_accuracy: 0.9576\n",
      "Epoch 117/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.2708 - val_accuracy: 0.9541\n",
      "Epoch 118/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.2742 - val_accuracy: 0.9541\n",
      "Epoch 119/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.2675 - val_accuracy: 0.9576\n",
      "Epoch 120/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.2738 - val_accuracy: 0.9541\n",
      "Epoch 121/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2738 - val_accuracy: 0.9541\n",
      "Epoch 122/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2746 - val_accuracy: 0.9541\n",
      "Epoch 123/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2744 - val_accuracy: 0.9541\n",
      "Epoch 124/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.2847 - val_accuracy: 0.9541\n",
      "Epoch 125/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.2720 - val_accuracy: 0.9576\n",
      "Epoch 126/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2787 - val_accuracy: 0.9541\n",
      "Epoch 127/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2831 - val_accuracy: 0.9541\n",
      "Epoch 128/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 0.2673 - val_accuracy: 0.9541\n",
      "Epoch 129/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.2780 - val_accuracy: 0.9541\n",
      "Epoch 130/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2846 - val_accuracy: 0.9541\n",
      "Epoch 131/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.2872 - val_accuracy: 0.9541\n",
      "Epoch 132/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2796 - val_accuracy: 0.9576\n",
      "Epoch 133/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.2844 - val_accuracy: 0.9541\n",
      "Epoch 134/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.2847 - val_accuracy: 0.9541\n",
      "Epoch 135/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2861 - val_accuracy: 0.9541\n",
      "Epoch 136/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.2866 - val_accuracy: 0.9541\n",
      "Epoch 137/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.2832 - val_accuracy: 0.9576\n",
      "Epoch 138/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.2936 - val_accuracy: 0.9541\n",
      "Epoch 139/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2813 - val_accuracy: 0.9541\n",
      "Epoch 140/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.2873 - val_accuracy: 0.9541\n",
      "Epoch 141/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.2982 - val_accuracy: 0.9541\n",
      "Epoch 142/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2830 - val_accuracy: 0.9541\n",
      "Epoch 143/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.3008 - val_accuracy: 0.9541\n",
      "Epoch 144/250\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.2963 - val_accuracy: 0.9541\n",
      "Epoch 145/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.2765 - val_accuracy: 0.9541\n",
      "Epoch 146/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.3002 - val_accuracy: 0.9541\n",
      "Epoch 147/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.2900 - val_accuracy: 0.9541\n",
      "Epoch 148/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.2989 - val_accuracy: 0.9541\n",
      "Epoch 149/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.3015 - val_accuracy: 0.9541\n",
      "Epoch 150/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.2975 - val_accuracy: 0.9576\n",
      "Epoch 151/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.2995 - val_accuracy: 0.9541\n",
      "Epoch 152/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.2973 - val_accuracy: 0.9541\n",
      "Epoch 153/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.3006 - val_accuracy: 0.9541\n",
      "Epoch 154/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.3101 - val_accuracy: 0.9541\n",
      "Epoch 155/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.3005 - val_accuracy: 0.9541\n",
      "Epoch 156/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2971 - val_accuracy: 0.9541\n",
      "Epoch 157/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.2975 - val_accuracy: 0.9541\n",
      "Epoch 158/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.3052 - val_accuracy: 0.9541\n",
      "Epoch 159/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3117 - val_accuracy: 0.9541\n",
      "Epoch 160/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.2918 - val_accuracy: 0.9541\n",
      "Epoch 161/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.3060 - val_accuracy: 0.9541\n",
      "Epoch 162/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.3056 - val_accuracy: 0.9576\n",
      "Epoch 163/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.3068 - val_accuracy: 0.9541\n",
      "Epoch 164/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.2973 - val_accuracy: 0.9541\n",
      "Epoch 165/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.2980 - val_accuracy: 0.9541\n",
      "Epoch 166/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.3211 - val_accuracy: 0.9541\n",
      "Epoch 167/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.3010 - val_accuracy: 0.9541\n",
      "Epoch 168/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.3080 - val_accuracy: 0.9541\n",
      "Epoch 169/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.3097 - val_accuracy: 0.9541\n",
      "Epoch 170/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.3033 - val_accuracy: 0.9505\n",
      "Epoch 171/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.3229 - val_accuracy: 0.9541\n",
      "Epoch 172/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.3047 - val_accuracy: 0.9541\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.3103 - val_accuracy: 0.9541\n",
      "Epoch 174/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.3237 - val_accuracy: 0.9470\n",
      "Epoch 175/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.2965 - val_accuracy: 0.9541\n",
      "Epoch 176/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.3177 - val_accuracy: 0.9541\n",
      "Epoch 177/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.3079 - val_accuracy: 0.9505\n",
      "Epoch 178/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 0.3116 - val_accuracy: 0.9505\n",
      "Epoch 179/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.3209 - val_accuracy: 0.9541\n",
      "Epoch 180/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.3059 - val_accuracy: 0.9541\n",
      "Epoch 181/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.3143 - val_accuracy: 0.9505\n",
      "Epoch 182/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.3166 - val_accuracy: 0.9505\n",
      "Epoch 183/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.3159 - val_accuracy: 0.9505\n",
      "Epoch 184/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.3095 - val_accuracy: 0.9505\n",
      "Epoch 185/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.3238 - val_accuracy: 0.9541\n",
      "Epoch 186/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3103 - val_accuracy: 0.9505\n",
      "Epoch 187/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.3274 - val_accuracy: 0.9541\n",
      "Epoch 188/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.3189 - val_accuracy: 0.9541\n",
      "Epoch 189/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.3271 - val_accuracy: 0.9541\n",
      "Epoch 190/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.3123 - val_accuracy: 0.9541\n",
      "Epoch 191/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.3208 - val_accuracy: 0.9541\n",
      "Epoch 192/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.3197 - val_accuracy: 0.9505\n",
      "Epoch 193/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.3241 - val_accuracy: 0.9541\n",
      "Epoch 194/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.3189 - val_accuracy: 0.9541\n",
      "Epoch 195/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.3205 - val_accuracy: 0.9541\n",
      "Epoch 196/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9541\n",
      "Epoch 197/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3153 - val_accuracy: 0.9541\n",
      "Epoch 198/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.3273 - val_accuracy: 0.9541\n",
      "Epoch 199/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.3212 - val_accuracy: 0.9541\n",
      "Epoch 200/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.3210 - val_accuracy: 0.9541\n",
      "Epoch 201/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.3300 - val_accuracy: 0.9541\n",
      "Epoch 202/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.3164 - val_accuracy: 0.9505\n",
      "Epoch 203/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3253 - val_accuracy: 0.9505\n",
      "Epoch 204/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.3365 - val_accuracy: 0.9541\n",
      "Epoch 205/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9505\n",
      "Epoch 206/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.3486 - val_accuracy: 0.9505\n",
      "Epoch 207/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.3246 - val_accuracy: 0.9505\n",
      "Epoch 208/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.3258 - val_accuracy: 0.9541\n",
      "Epoch 209/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.3273 - val_accuracy: 0.9541\n",
      "Epoch 210/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.3376 - val_accuracy: 0.9541\n",
      "Epoch 211/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 0.3054 - val_accuracy: 0.9611\n",
      "Epoch 212/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3735 - val_accuracy: 0.9505\n",
      "Epoch 213/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.3308 - val_accuracy: 0.9541\n",
      "Epoch 214/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.3371 - val_accuracy: 0.9505\n",
      "Epoch 215/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.3334 - val_accuracy: 0.9505\n",
      "Epoch 216/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.3366 - val_accuracy: 0.9505\n",
      "Epoch 217/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.3295 - val_accuracy: 0.9541\n",
      "Epoch 218/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.3300 - val_accuracy: 0.9541\n",
      "Epoch 219/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.3314 - val_accuracy: 0.9541\n",
      "Epoch 220/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.3331 - val_accuracy: 0.9505\n",
      "Epoch 221/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.3338 - val_accuracy: 0.9505\n",
      "Epoch 222/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.3350 - val_accuracy: 0.9541\n",
      "Epoch 223/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.3287 - val_accuracy: 0.9505\n",
      "Epoch 224/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3207 - val_accuracy: 0.9541\n",
      "Epoch 225/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.3413 - val_accuracy: 0.9541\n",
      "Epoch 226/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.3346 - val_accuracy: 0.9541\n",
      "Epoch 227/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.3401 - val_accuracy: 0.9541\n",
      "Epoch 228/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3413 - val_accuracy: 0.9541\n",
      "Epoch 229/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 0.3307 - val_accuracy: 0.9541\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 0.3352 - val_accuracy: 0.9505\n",
      "Epoch 231/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3331 - val_accuracy: 0.9541\n",
      "Epoch 232/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3409 - val_accuracy: 0.9541\n",
      "Epoch 233/250\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.3360 - val_accuracy: 0.9505\n",
      "Epoch 234/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 0.3293 - val_accuracy: 0.9541\n",
      "Epoch 235/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.3441 - val_accuracy: 0.9541\n",
      "Epoch 236/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.3351 - val_accuracy: 0.9505\n",
      "Epoch 237/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.3518 - val_accuracy: 0.9470\n",
      "Epoch 238/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.3409 - val_accuracy: 0.9541\n",
      "Epoch 239/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.3330 - val_accuracy: 0.9541\n",
      "Epoch 240/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3334 - val_accuracy: 0.9541\n",
      "Epoch 241/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3321 - val_accuracy: 0.9505\n",
      "Epoch 242/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.3378 - val_accuracy: 0.9541\n",
      "Epoch 243/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3354 - val_accuracy: 0.9505\n",
      "Epoch 244/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.3399 - val_accuracy: 0.9541\n",
      "Epoch 245/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3324 - val_accuracy: 0.9541\n",
      "Epoch 246/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.3481 - val_accuracy: 0.9541\n",
      "Epoch 247/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.3390 - val_accuracy: 0.9505\n",
      "Epoch 248/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.3438 - val_accuracy: 0.9541\n",
      "Epoch 249/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.3435 - val_accuracy: 0.9541\n",
      "Epoch 250/250\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.3356 - val_accuracy: 0.9541\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.9541\n",
      "Final accuracy on test data: 95.41%\n"
     ]
    }
   ],
   "source": [
    "# Assuming the model has been defined and compiled as shown before.\n",
    "# Splitting the dataset into training and test sets\n",
    "# This assumes you want to use 80% of the data for training and 20% for testing.\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(dataset) * split_ratio)\n",
    "train_data = dataset[:split_index]\n",
    "test_data = dataset[split_index:]\n",
    "\n",
    "# Training Data Preparation\n",
    "reviews_train = np.array([sample['x'] for sample in train_data])\n",
    "labels_train = np.array([sample['y'] for sample in train_data]).reshape([-1,1])\n",
    "\n",
    "# Test Data Preparation\n",
    "reviews_test = np.array([sample['x'] for sample in test_data])\n",
    "labels_test = np.array([sample['y'] for sample in test_data]).reshape([-1,1])\n",
    "\n",
    "# Train the model for 250 epochs\n",
    "history = model.fit(reviews_train, labels_train, epochs=250, batch_size=100, shuffle=True, validation_data=(reviews_test, labels_test))\n",
    "\n",
    "# Evaluate the model's performance on test data\n",
    "loss, acc = model.evaluate(reviews_test, labels_test)\n",
    "print(\"Final accuracy on test data: {:.2f}%\".format(acc * 100))\n",
    "\n",
    "# The code above provides a more specific approach based on the data processing provided.\n",
    "# You can run this in a TensorFlow 2.x environment to train the model and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb8b22",
   "metadata": {},
   "source": [
    "We can now examine what our model has learned, seeing how it responds to word vectors for different words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92045e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "exciting [[1.]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "hated [[2.8573204e-31]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boring [[2.2877814e-24]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "loved [[1.]]\n"
     ]
    }
   ],
   "source": [
    "# Check some words using TensorFlow 2.x\n",
    "words_to_test = [\"exciting\", \"hated\", \"boring\", \"loved\"]\n",
    "\n",
    "for word in words_to_test:\n",
    "    word_embedding = normalized_embeddings[index[word]].reshape(1, 300)\n",
    "    predicted_prob = model.predict(word_embedding)\n",
    "    print(word, predicted_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b295d0c",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- We loop over the words in words_to_test.\n",
    "- For each word, we fetch its embedding and reshape it to be compatible with the model's input shape.\n",
    "- We use the `model.predict` method to get the model's output probability for the given word embedding.\n",
    "- Finally, the word and its corresponding predicted probability are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8465ba",
   "metadata": {},
   "source": [
    "The results you've received indicate the model's output probabilities for the words \"exciting\", \"hated\", \"boring\", and \"loved\". Let's interpret these results:\n",
    "\n",
    "exciting: The model predicted a probability of 1.0 (or very close to 1), suggesting that the model associates the word \"exciting\" with a positive sentiment.\n",
    "\n",
    "hated: The model predicted a probability extremely close to 0, as indicated by the very small scientific notation value. This suggests that the model associates the word \"hated\" with a negative sentiment.\n",
    "\n",
    "boring: Similarly, the word \"boring\" also gets a probability close to 0, suggesting a negative sentiment.\n",
    "\n",
    "loved: The probability for \"loved\" is 1.0, indicating a strong positive sentiment.\n",
    "\n",
    "These results are in line with what we'd expect. Words like \"exciting\" and \"loved\" are associated with positive sentiments, while words like \"hated\" and \"boring\" are linked to negative sentiments.\n",
    "\n",
    "It's good to see the model's predictions aligning with our intuitive understanding of these words' sentiments. This suggests that the model has learned meaningful representations from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde15778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "inspired [[1.]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "annoying [[7.6847117e-25]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "sad [[1.1678653e-16]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "recommend [[0.9999999]]\n"
     ]
    }
   ],
   "source": [
    "# Testing my own words\n",
    "words_to_test = [\"inspired\", \"annoying\", \"sad\", \"recommend\"]\n",
    "\n",
    "for word in words_to_test:\n",
    "    word_embedding = normalized_embeddings[index[word]].reshape(1, 300)\n",
    "    predicted_prob = model.predict(word_embedding)\n",
    "    print(word, predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0829a1",
   "metadata": {},
   "source": [
    "This model works great for such a simple dataset, but does a little less well on something more complex. `movie-pang02.txt`, for instance, has 2000 longer, more complex movie reviews. It's in the same format as our simple dataset. On those longer reviews, this model achieves only 60-80% accuracy. (Increasing the number of epochs to, say, 1000, does help.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225d0b4",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNNs)\n",
    "\n",
    "In the context of deep learning, natural language is commonly modeled with Recurrent Neural Networks (RNNs).\n",
    "RNNs pass the output of a neuron back to the input of the next time step of the same neuron.\n",
    "These directed cycles in the RNN architecture gives them the ability to model temporal dynamics, making them particularly suited for modeling sequences (e.g. text).\n",
    "We can visualize an RNN layer as follows:\n",
    "\n",
    "<img src=\"Figures/basic_RNN.PNG\" alt=\"basic_RNN\" style=\"width: 80px;\"/>\n",
    "<center>Figure from *Understanding LSTMs*. https://colah.github.io/posts/2015-08-Understanding-LSTMs/</center>\n",
    "\n",
    "We can unroll an RNN through time, making the sequence aspect of them more obvious:\n",
    "\n",
    "<img src=\"Figures/unrolled_RNN.PNG\" alt=\"basic_RNN\" style=\"width: 400px;\"/>\n",
    "<center>Figure from *Understanding LSTMs*. https://colah.github.io/posts/2015-08-Understanding-LSTMs/</center>\n",
    "\n",
    "#### RNNs in TensorFlow\n",
    "How would we implement an RNN in TensorFlow? Given the different forms of RNNs, there are quite a few ways, but we'll stick to a simple one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75870a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, import TensorFlow first\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141cc3d",
   "metadata": {},
   "source": [
    "Let's assume we have our inputs in word embedding form already, say of dimensionality 100. We'll use a minibatch size of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d6fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = 16\n",
    "x_dim = 100\n",
    "\n",
    "# In TensorFlow 2.x, you don't define placeholders. Instead, when defining a model:\n",
    "# model = tf.keras.Sequential([...])\n",
    "# You'll specify the input shape in the first layer:\n",
    "# tf.keras.layers.Input(shape=(x_dim,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e19383",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The code initializes two variables, mb and x_dim, representing the mini-batch size and the dimensionality of the word embeddings, respectively. These values were previously mentioned in the preceding markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4233c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 64\n",
    "\n",
    "# For projecting the input\n",
    "U = tf.Variable(tf.random.truncated_normal([x_dim, h_dim], stddev=0.1))\n",
    "\n",
    "# For projecting the previous state\n",
    "W = tf.Variable(tf.random.truncated_normal([h_dim, h_dim], stddev=0.1))\n",
    "\n",
    "# For projecting the output\n",
    "V = tf.Variable(tf.random.truncated_normal([h_dim, x_dim], stddev=0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b96db8",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The variable `h_dim` is set to 64, which is the dimension of the hidden layer or state in the RNN.\n",
    "- `U`: This is the weight matrix for projecting the input. Its shape is `[x_dim, h_dim]`, meaning it will transform data from the input dimension `x_di`m to the hidden layer dimension `h_dim`.\n",
    "- `W`: This is the weight matrix for projecting the previous state. Its shape is `[h_dim, h_dim]`, allowing it to transform the hidden state from one time step to the next.\n",
    "- `V`: This is the weight matrix for projecting the output. It will transform data from the hidden layer dimension `h_dim` back to the input dimension `x_dim`.\n",
    "- All these matrices are initialized with truncated normal distributions having a standard deviation of 0.1, which is a common initialization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ce3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_step(x, h):\n",
    "    h_next = tf.tanh(tf.matmul(x, U) + tf.matmul(h, W))\n",
    "    \n",
    "    output = tf.matmul(h_next, V)\n",
    "    return output, h_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c38b67",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- This function, `RNN_step`, takes in two parameters: `x`, the input data for the current time step, and `h`, the hidden state from the previous time step.\n",
    "- The function calculates `h_next`, the next hidden state, by:\n",
    "        - Multiplying the input x by the weight matrix U and the previous hidden state h by the weight matrix W.\n",
    "        - Summing these two results.\n",
    "        - Applying the `tanh` activation function.\n",
    "- The output for the current time step is then computed by multiplying `h_next` with the weight matrix `V`.\n",
    "- The function returns the computed output and the next hidden state h_next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "878b2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y1 dimensions: (16, 100)\n",
      "Hidden state h1 dimensions: (16, 64)\n"
     ]
    }
   ],
   "source": [
    "# Initialize hidden state to 0\n",
    "h0 = tf.zeros([mb, h_dim])\n",
    "\n",
    "# Define x1 as some sample input data for the first time step\n",
    "x1 = tf.random.normal([mb, x_dim])\n",
    "\n",
    "# Forward pass of one RNN step for time step t=1\n",
    "y1, h1 = RNN_step(x1, h0)\n",
    "\n",
    "print(\"Output y1 dimensions:\", y1.shape)\n",
    "print(\"Hidden state h1 dimensions:\", h1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc7a727",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The initial hidden state, `h0`, is initialized to a matrix of zeros with dimensions `[mb, h_dim]`, where `mb` is the mini-batch size and `h_dim` is the hidden layer dimension (previously set to 64).\n",
    "- The function `RNN_ste`p is then called with the input for the first time step `(x1)` and the initial hidden state `(h0)`. This gives the output `y1` and the next hidden state `h1` for time step `t=1`.\n",
    "- The dimensions of the output `y1` and the hidden state `h1` are then printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74513b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y2 dimensions: (16, 100)\n",
      "Hidden state h2 dimensions: (16, 64)\n"
     ]
    }
   ],
   "source": [
    "# Simulate some sample input data for the second time step\n",
    "x2 = tf.random.normal([mb, x_dim])\n",
    "\n",
    "# Forward pass of one RNN step for time step t=2\n",
    "y2, h2 = RNN_step(x2, h1)\n",
    "\n",
    "print(\"Output y2 dimensions:\", y2.shape)\n",
    "print(\"Hidden state h2 dimensions:\", h2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0887cf6",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The code defines a new placeholder `x2` to represent the input for the second time step.\n",
    "- The `RNN_step` function is then called again, this time with `x2` as the input and `h1` (the hidden state from the previous time step) as the previous state.\n",
    "- This produces `y2`, the output for the second time step, and `h2`, the hidden state to be passed to the next time step.\n",
    "- The dimensions of `y2` and `h2` are then printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c8ed31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x dimensions:\n",
      "[TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100]), TensorShape([16, 100])]\n",
      "\n",
      "h dimensions:\n",
      "[TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64]), TensorShape([16, 64])]\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\n",
    "num_steps = 10\n",
    "\n",
    "# List of inputs and hidden states\n",
    "xs = []\n",
    "hs = []\n",
    "\n",
    "# Build RNN\n",
    "rnn = tf.keras.layers.SimpleRNNCell(h_dim)\n",
    "\n",
    "# Initialize hidden state to zero\n",
    "h_t  = tf.zeros([mb, h_dim])\n",
    "\n",
    "for t in range(num_steps):\n",
    "    x_t = tf.random.normal([mb, x_dim])  # Use sample data in place of placeholders\n",
    "    h_t, _ = rnn(x_t, [h_t])\n",
    "    \n",
    "    xs.append(x_t)\n",
    "    hs.append(h_t)\n",
    "    \n",
    "print(\"x dimensions:\")\n",
    "print([x_t.shape for x_t in xs])\n",
    "print(\"\\nh dimensions:\")\n",
    "print([h_t.shape for h_t in hs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b61f1",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The code specifies that the RNN will be unrolled for `num_steps` time steps, which is set to `10` in this case.\n",
    "- Empty lists, `xs` and `hs`, are created to store the inputs and hidden states at each time step, respectively.\n",
    "- The RNN is built using TensorFlow's BasicRNNCell from the `tf.contrib.rnn` module. For Tensorflow 2.x We use `tf.keras.layers.SimpleRNNCell` in place of `tf.contrib.rnn.BasicRNNCell`.\n",
    "- The hidden state `h_t` is initialized to zeros.\n",
    "\n",
    "Within the loop:\n",
    "- A new placeholder `x_t` is created for each time step's input.\n",
    "- The built-in RNN cell is called with `x_t` and `h_t` to get the new hidden state.\n",
    "- The input and hidden state are then stored in their respective lists.\n",
    "\n",
    "- The dimensions of all inputs and hidden states are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a04e3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ea5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803e42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429224ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54495f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74197807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9220954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
