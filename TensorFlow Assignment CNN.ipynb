{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8387bcbc",
   "metadata": {},
   "source": [
    "# TensorFlow Assignment: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc0ae6",
   "metadata": {},
   "source": [
    "Build a 2-layer CNN for MNIST digit classfication. Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image -> convolution (32 5x5 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> convolution (64 5x5 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> fully connected (256 hidden units) -> nonlinearity (ReLU) -> fully connected (10 hidden units) -> softmax\n",
    "\n",
    "Some tips:\n",
    "\n",
    "The CNN model might take a while to train. Depending on your machine, you might expect this to take up to half an hour. If you see your validation performance start to plateau, you can kill the training.\n",
    "\n",
    "Since CNNs a more complex than the logistic regression and MLP models you've worked with before, so you may find it helpful to use a more advanced optimizer. You're model will train faster if you use tf.train.AdamOptimizer instead of tf.train.GradientDescentOptimizer. A learning rate of 1e-4 is a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ada7d",
   "metadata": {},
   "source": [
    "***Let's first import all the necessary modules and load the MNIST dataset. Please note that TensorFlow offers a handy function, tf.keras.datasets.mnist.load_data(), which allows us to download and load the MNIST dataset directly:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6970e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7284b",
   "metadata": {},
   "source": [
    "***Now, let's build the CNN architecture as you have described:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d40d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images to have a single color channel (they're grayscale)\n",
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "test_images = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the first convolutional layer with 32 5x5 filters and ReLU activation function\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Add a 2x2 max pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add the second convolutional layer with 64 5x5 filters and ReLU activation function\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "\n",
    "# Add another 2x2 max pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the tensor output from the previous layer\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a fully connected layer with 256 hidden units and ReLU activation function\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Add a fully connected layer with 10 hidden units\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# Add a softmax layer for classification\n",
    "model.add(layers.Softmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24eed7e",
   "metadata": {},
   "source": [
    "***Now, compile and train the model:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "949d2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "313/313 - 1s - loss: 0.0285 - accuracy: 0.9925 - 1s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=6)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642b806",
   "metadata": {},
   "source": [
    "***Please note that the model's fit method starts the training process. The number of epochs is the number of times the learning algorithm will work through the entire training dataset. I've set it to 5, but you can experiment with this number.\n",
    "\n",
    "Finally, the model is evaluated on the test dataset, and the test accuracy is printed. Remember that the accuracy on the test dataset is a measure of how well the model generalizes to unseen data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c25f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d45ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80ef4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
