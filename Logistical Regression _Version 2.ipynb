{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798bcc37",
   "metadata": {},
   "source": [
    "The first cell is a Markdown cell that contains a heading: \"Introduction to Logistic Regression in TensorFlow\". This indicates that the notebook is about explaining how to implement logistic regression, a popular machine learning algorithm, using TensorFlow, a powerful library for numerical computation, particularly suited for large-scale Machine Learning.\n",
    "\n",
    "Logistic Regression is a type of algorithm used for classification problems, where the aim is to predict a binary outcome (1/0, Yes/No, True/False) given a set of independent variables. In the context of Machine Learning, TensorFlow provides the tools to define, train, and utilize this logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391bdec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfc1ed",
   "metadata": {},
   "source": [
    "This cell is setting up the necessary Python libraries for the notebook:\n",
    "\n",
    "%matplotlib inline is a command specific to Jupyter notebooks that allows the output of plotting commands to be displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n",
    "\n",
    "import numpy as np is importing the numpy library and aliasing it as np. Numpy is a popular library in Python that provides support for arrays and matrices, along with a large collection of mathematical functions to operate on these elements.\n",
    "\n",
    "import matplotlib.pyplot as plt is importing the pyplot sublibrary from matplotlib and aliasing it as plt. Matplotlib is a plotting library in Python and pyplot provides a MATLAB-like interface for making plots and graphs.\n",
    "\n",
    "import tensorflow as tf is importing the tensorflow library and aliasing it as tf. Tensorflow is a powerful library for numerical computation and is commonly used for machine learning tasks.\n",
    "\n",
    "from tqdm import trange is importing the trange function from the tqdm library. tqdm is a library in Python that provides progress bars for loops and trange is a version of the built-in range function that includes a progress bar.\n",
    "\n",
    "Think of these as gathering your tools before starting a project. You need to know what kind of task you are about to undertake and gather the appropriate tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c42900",
   "metadata": {},
   "source": [
    "The third cell is a Markdown cell with the text \"MNIST Dataset\". This is a subheading, indicating that the next section of the notebook will be discussing the MNIST dataset.\n",
    "\n",
    "The MNIST (Modified National Institute of Standards and Technology) dataset is a large database of handwritten digits commonly used for training various image processing systems. It contains 60,000 training images and 10,000 testing images. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels. This makes it a good dataset for beginners trying to learn techniques and methodologies for machine learning and pattern recognition on real-world data while not being too complex in size or computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8bf7f",
   "metadata": {},
   "source": [
    "\"The MNIST dataset is a very popular machine learning dataset, consisting of 70,000 grayscale images of handwritten digits, of dimensions 28x28. We'll be using it as our example for this section of the tutorial, with the goal being to predict the digit in each image.\n",
    "\n",
    "mnist\n",
    "\n",
    "Since it's such a common (and small) dataset, TensorFlow has commands for downloading and formatting the dataset conveniently baked in already.\"\n",
    "\n",
    "The text refers to an image 'mnist.png' in the 'Figures' directory, which presumably shows a sample of the MNIST dataset. Since I can't display images here, you might want to check it out in the original notebook or look up the MNIST dataset online to see what it looks like.\n",
    "\n",
    "The gist of this cell is that MNIST is a dataset of 70,000 28x28 grayscale images of handwritten digits. It's widely used for teaching machine learning, and the goal in this notebook is to create a model that can predict the digit represented in each image.\n",
    "\n",
    "TensorFlow conveniently has built-in functions to download and format this dataset, which will be demonstrated in the upcoming cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355da55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./datasets/MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf902c",
   "metadata": {},
   "source": [
    "This cell is loading the MNIST dataset from TensorFlow's built-in functions:\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data is importing the input_data module from TensorFlow's mnist examples. This module contains functions to load the MNIST dataset.\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./datasets/MNIST_data/\", one_hot=True) is calling the read_data_sets function from the input_data module. This function downloads the MNIST dataset and loads it into memory. The data is stored in the \"./datasets/MNIST_data/\" directory. The one_hot=True argument specifies that the labels (which are the digits 0-9) should be represented in one-hot encoded format. One-hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to improve predictions. For a label in n classes, a one-hot encoded label is a 1D array of length n filled with 0s except for the index of the class, which is set to 1.\n",
    "\n",
    "For example, for MNIST, since we have 10 digits (0-9), the digit 3 in one-hot encoding format will be represented as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]. This type of representation is commonly used in machine learning when dealing with categorical labels.\n",
    "\n",
    "The stdout indicates there are some deprecation warnings, which means that the TensorFlow library has updated since this code was written and some functions used here are now outdated. This is something we might need to address to ensure the code is up to date.\n",
    "\n",
    " The new preferred method is to use the tensorflow_datasets library. This library is not built into TensorFlow, but it is made to work well with it.\n",
    "\n",
    "Here is the updated code to load the MNIST dataset using the tensorflow_datasets library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ab46d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.78 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.78 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.78 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|          | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.78 url/s]8 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.78 url/s]8 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.78 url/s]8 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  4.18 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.78 url/s]\n",
      "Dl Size...:  10%|█         | 1/10 [00:00<00:02,  3.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]8 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  10%|█         | 1/10 [00:00<00:02,  3.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]8 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  10%|█         | 1/10 [00:00<00:02,  3.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]8 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|██        | 2/10 [00:00<00:02,  3.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  4.18 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]0 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|██        | 2/10 [00:00<00:02,  3.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]\n",
      "Dl Size...:  30%|███       | 3/10 [00:00<00:01,  6.36 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]\n",
      "Dl Size...:  40%|████      | 4/10 [00:00<00:00,  6.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]\n",
      "Dl Size...:  50%|█████     | 5/10 [00:00<00:00,  7.24 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.43 url/s]\n",
      "Dl Size...:  60%|██████    | 6/10 [00:00<00:00,  7.14 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  9.43 url/s]\n",
      "Dl Size...:  70%|███████   | 7/10 [00:01<00:00,  7.43 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  9.43 url/s]\n",
      "Dl Size...:  80%|████████  | 8/10 [00:01<00:00,  7.63 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  9.43 url/s]\n",
      "Dl Size...:  90%|█████████ | 9/10 [00:01<00:00,  7.78 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  9.43 url/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  7.88 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  9.43 url/s]0 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  7.88 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  9.43 url/s]0 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  7.88 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|███████▌  | 3/4 [00:01<00:00,  8.10 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  9.43 url/s]3 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  7.88 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:01<00:00,  2.39 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  5.97 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.38 url/s]\n",
      "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 55 examples [00:00, 544.54 examples/s]\u001b[A\n",
      "Generating train examples...: 260 examples [00:00, 1418.17 examples/s]\u001b[A\n",
      "Generating train examples...: 465 examples [00:00, 1705.10 examples/s]\u001b[A\n",
      "Generating train examples...: 677 examples [00:00, 1861.06 examples/s]\u001b[A\n",
      "Generating train examples...: 879 examples [00:00, 1918.10 examples/s]\u001b[A\n",
      "Generating train examples...: 1083 examples [00:00, 1952.80 examples/s]\u001b[A\n",
      "Generating train examples...: 1283 examples [00:00, 1968.16 examples/s]\u001b[A\n",
      "Generating train examples...: 1480 examples [00:00, 1962.51 examples/s]\u001b[A\n",
      "Generating train examples...: 1686 examples [00:00, 1986.69 examples/s]\u001b[A\n",
      "Generating train examples...: 1891 examples [00:01, 1999.98 examples/s]\u001b[A\n",
      "Generating train examples...: 2096 examples [00:01, 2015.20 examples/s]\u001b[A\n",
      "Generating train examples...: 2301 examples [00:01, 2025.74 examples/s]\u001b[A\n",
      "Generating train examples...: 2508 examples [00:01, 2039.11 examples/s]\u001b[A\n",
      "Generating train examples...: 2715 examples [00:01, 2042.27 examples/s]\u001b[A\n",
      "Generating train examples...: 2925 examples [00:01, 2053.46 examples/s]\u001b[A\n",
      "Generating train examples...: 3131 examples [00:01, 2049.28 examples/s]\u001b[A\n",
      "Generating train examples...: 3341 examples [00:01, 2064.45 examples/s]\u001b[A\n",
      "Generating train examples...: 3551 examples [00:01, 2075.09 examples/s]\u001b[A\n",
      "Generating train examples...: 3759 examples [00:01, 2058.06 examples/s]\u001b[A\n",
      "Generating train examples...: 3965 examples [00:02, 2052.52 examples/s]\u001b[A\n",
      "Generating train examples...: 4177 examples [00:02, 2066.48 examples/s]\u001b[A\n",
      "Generating train examples...: 4385 examples [00:02, 2070.49 examples/s]\u001b[A\n",
      "Generating train examples...: 4601 examples [00:02, 2090.98 examples/s]\u001b[A\n",
      "Generating train examples...: 4811 examples [00:02, 2087.45 examples/s]\u001b[A\n",
      "Generating train examples...: 5020 examples [00:02, 2088.19 examples/s]\u001b[A\n",
      "Generating train examples...: 5229 examples [00:02, 2088.73 examples/s]\u001b[A\n",
      "Generating train examples...: 5439 examples [00:02, 2092.10 examples/s]\u001b[A\n",
      "Generating train examples...: 5654 examples [00:02, 2103.14 examples/s]\u001b[A\n",
      "Generating train examples...: 5868 examples [00:02, 2107.86 examples/s]\u001b[A\n",
      "Generating train examples...: 6085 examples [00:03, 2120.11 examples/s]\u001b[A\n",
      "Generating train examples...: 6298 examples [00:03, 2116.72 examples/s]\u001b[A\n",
      "Generating train examples...: 6510 examples [00:03, 2111.40 examples/s]\u001b[A\n",
      "Generating train examples...: 6724 examples [00:03, 2113.63 examples/s]\u001b[A\n",
      "Generating train examples...: 6936 examples [00:03, 2115.52 examples/s]\u001b[A\n",
      "Generating train examples...: 7148 examples [00:03, 2110.56 examples/s]\u001b[A\n",
      "Generating train examples...: 7360 examples [00:03, 2107.09 examples/s]\u001b[A\n",
      "Generating train examples...: 7575 examples [00:03, 2113.60 examples/s]\u001b[A\n",
      "Generating train examples...: 7787 examples [00:03, 2115.51 examples/s]\u001b[A\n",
      "Generating train examples...: 8002 examples [00:03, 2119.48 examples/s]\u001b[A\n",
      "Generating train examples...: 8219 examples [00:04, 2128.20 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 8432 examples [00:04, 2085.20 examples/s]\u001b[A\n",
      "Generating train examples...: 8647 examples [00:04, 2098.11 examples/s]\u001b[A\n",
      "Generating train examples...: 8864 examples [00:04, 2113.11 examples/s]\u001b[A\n",
      "Generating train examples...: 9081 examples [00:04, 2123.67 examples/s]\u001b[A\n",
      "Generating train examples...: 9295 examples [00:04, 2128.50 examples/s]\u001b[A\n",
      "Generating train examples...: 9511 examples [00:04, 2131.53 examples/s]\u001b[A\n",
      "Generating train examples...: 9728 examples [00:04, 2136.64 examples/s]\u001b[A\n",
      "Generating train examples...: 9943 examples [00:04, 2140.62 examples/s]\u001b[A\n",
      "Generating train examples...: 10159 examples [00:04, 2140.02 examples/s]\u001b[A\n",
      "Generating train examples...: 10374 examples [00:05, 2142.99 examples/s]\u001b[A\n",
      "Generating train examples...: 10590 examples [00:05, 2141.68 examples/s]\u001b[A\n",
      "Generating train examples...: 10807 examples [00:05, 2143.72 examples/s]\u001b[A\n",
      "Generating train examples...: 11024 examples [00:05, 2145.17 examples/s]\u001b[A\n",
      "Generating train examples...: 11240 examples [00:05, 2149.59 examples/s]\u001b[A\n",
      "Generating train examples...: 11457 examples [00:05, 2149.27 examples/s]\u001b[A\n",
      "Generating train examples...: 11672 examples [00:05, 2149.48 examples/s]\u001b[A\n",
      "Generating train examples...: 11887 examples [00:05, 2124.24 examples/s]\u001b[A\n",
      "Generating train examples...: 12101 examples [00:05, 2128.92 examples/s]\u001b[A\n",
      "Generating train examples...: 12317 examples [00:05, 2131.83 examples/s]\u001b[A\n",
      "Generating train examples...: 12532 examples [00:06, 2137.24 examples/s]\u001b[A\n",
      "Generating train examples...: 12748 examples [00:06, 2144.03 examples/s]\u001b[A\n",
      "Generating train examples...: 12963 examples [00:06, 2133.06 examples/s]\u001b[A\n",
      "Generating train examples...: 13180 examples [00:06, 2137.69 examples/s]\u001b[A\n",
      "Generating train examples...: 13394 examples [00:06, 2125.73 examples/s]\u001b[A\n",
      "Generating train examples...: 13609 examples [00:06, 2132.94 examples/s]\u001b[A\n",
      "Generating train examples...: 13825 examples [00:06, 2141.01 examples/s]\u001b[A\n",
      "Generating train examples...: 14042 examples [00:06, 2143.26 examples/s]\u001b[A\n",
      "Generating train examples...: 14257 examples [00:06, 2119.96 examples/s]\u001b[A\n",
      "Generating train examples...: 14474 examples [00:06, 2128.48 examples/s]\u001b[A\n",
      "Generating train examples...: 14692 examples [00:07, 2137.44 examples/s]\u001b[A\n",
      "Generating train examples...: 14909 examples [00:07, 2140.75 examples/s]\u001b[A\n",
      "Generating train examples...: 15127 examples [00:07, 2146.05 examples/s]\u001b[A\n",
      "Generating train examples...: 15343 examples [00:07, 2150.20 examples/s]\u001b[A\n",
      "Generating train examples...: 15561 examples [00:07, 2152.67 examples/s]\u001b[A\n",
      "Generating train examples...: 15778 examples [00:07, 2151.42 examples/s]\u001b[A\n",
      "Generating train examples...: 15994 examples [00:07, 2153.98 examples/s]\u001b[A\n",
      "Generating train examples...: 16210 examples [00:07, 2149.34 examples/s]\u001b[A\n",
      "Generating train examples...: 16428 examples [00:07, 2152.08 examples/s]\u001b[A\n",
      "Generating train examples...: 16646 examples [00:07, 2153.99 examples/s]\u001b[A\n",
      "Generating train examples...: 16862 examples [00:08, 2155.78 examples/s]\u001b[A\n",
      "Generating train examples...: 17078 examples [00:08, 2157.04 examples/s]\u001b[A\n",
      "Generating train examples...: 17295 examples [00:08, 2154.47 examples/s]\u001b[A\n",
      "Generating train examples...: 17511 examples [00:08, 2149.70 examples/s]\u001b[A\n",
      "Generating train examples...: 17729 examples [00:08, 2152.32 examples/s]\u001b[A\n",
      "Generating train examples...: 17946 examples [00:08, 2151.18 examples/s]\u001b[A\n",
      "Generating train examples...: 18162 examples [00:08, 2153.81 examples/s]\u001b[A\n",
      "Generating train examples...: 18378 examples [00:08, 2142.83 examples/s]\u001b[A\n",
      "Generating train examples...: 18593 examples [00:08, 2132.27 examples/s]\u001b[A\n",
      "Generating train examples...: 18809 examples [00:08, 2134.18 examples/s]\u001b[A\n",
      "Generating train examples...: 19026 examples [00:09, 2138.48 examples/s]\u001b[A\n",
      "Generating train examples...: 19243 examples [00:09, 2147.86 examples/s]\u001b[A\n",
      "Generating train examples...: 19458 examples [00:09, 2142.11 examples/s]\u001b[A\n",
      "Generating train examples...: 19673 examples [00:09, 2144.46 examples/s]\u001b[A\n",
      "Generating train examples...: 19888 examples [00:09, 2139.72 examples/s]\u001b[A\n",
      "Generating train examples...: 20104 examples [00:09, 2139.39 examples/s]\u001b[A\n",
      "Generating train examples...: 20319 examples [00:09, 2142.55 examples/s]\u001b[A\n",
      "Generating train examples...: 20536 examples [00:09, 2144.35 examples/s]\u001b[A\n",
      "Generating train examples...: 20752 examples [00:09, 2142.63 examples/s]\u001b[A\n",
      "Generating train examples...: 20969 examples [00:09, 2144.40 examples/s]\u001b[A\n",
      "Generating train examples...: 21186 examples [00:10, 2145.63 examples/s]\u001b[A\n",
      "Generating train examples...: 21404 examples [00:10, 2149.47 examples/s]\u001b[A\n",
      "Generating train examples...: 21622 examples [00:10, 2152.16 examples/s]\u001b[A\n",
      "Generating train examples...: 21839 examples [00:10, 2151.06 examples/s]\u001b[A\n",
      "Generating train examples...: 22057 examples [00:10, 2153.27 examples/s]\u001b[A\n",
      "Generating train examples...: 22273 examples [00:10, 2142.48 examples/s]\u001b[A\n",
      "Generating train examples...: 22491 examples [00:10, 2147.28 examples/s]\u001b[A\n",
      "Generating train examples...: 22706 examples [00:10, 2135.36 examples/s]\u001b[A\n",
      "Generating train examples...: 22922 examples [00:10, 2136.34 examples/s]\u001b[A\n",
      "Generating train examples...: 23139 examples [00:10, 2140.00 examples/s]\u001b[A\n",
      "Generating train examples...: 23355 examples [00:11, 2145.95 examples/s]\u001b[A\n",
      "Generating train examples...: 23570 examples [00:11, 2147.15 examples/s]\u001b[A\n",
      "Generating train examples...: 23785 examples [00:11, 2141.60 examples/s]\u001b[A\n",
      "Generating train examples...: 24002 examples [00:11, 2143.69 examples/s]\u001b[A\n",
      "Generating train examples...: 24217 examples [00:11, 2145.57 examples/s]\u001b[A\n",
      "Generating train examples...: 24433 examples [00:11, 2149.88 examples/s]\u001b[A\n",
      "Generating train examples...: 24651 examples [00:11, 2152.45 examples/s]\u001b[A\n",
      "Generating train examples...: 24868 examples [00:11, 2151.25 examples/s]\u001b[A\n",
      "Generating train examples...: 25084 examples [00:11, 2147.45 examples/s]\u001b[A\n",
      "Generating train examples...: 25299 examples [00:12, 2141.84 examples/s]\u001b[A\n",
      "Generating train examples...: 25515 examples [00:12, 2147.26 examples/s]\u001b[A\n",
      "Generating train examples...: 25730 examples [00:12, 2148.07 examples/s]\u001b[A\n",
      "Generating train examples...: 25947 examples [00:12, 2148.19 examples/s]\u001b[A\n",
      "Generating train examples...: 26164 examples [00:12, 2148.31 examples/s]\u001b[A\n",
      "Generating train examples...: 26383 examples [00:12, 2154.32 examples/s]\u001b[A\n",
      "Generating train examples...: 26599 examples [00:12, 2156.02 examples/s]\u001b[A\n",
      "Generating train examples...: 26816 examples [00:12, 2153.76 examples/s]\u001b[A\n",
      "Generating train examples...: 27035 examples [00:12, 2158.14 examples/s]\u001b[A\n",
      "Generating train examples...: 27251 examples [00:12, 2158.69 examples/s]\u001b[A\n",
      "Generating train examples...: 27467 examples [00:13, 2127.29 examples/s]\u001b[A\n",
      "Generating train examples...: 27680 examples [00:13, 2115.56 examples/s]\u001b[A\n",
      "Generating train examples...: 27892 examples [00:13, 2104.42 examples/s]\u001b[A\n",
      "Generating train examples...: 28103 examples [00:13, 2093.67 examples/s]\u001b[A\n",
      "Generating train examples...: 28314 examples [00:13, 2092.31 examples/s]\u001b[A\n",
      "Generating train examples...: 28524 examples [00:13, 2088.40 examples/s]\u001b[A\n",
      "Generating train examples...: 28733 examples [00:13, 2088.88 examples/s]\u001b[A\n",
      "Generating train examples...: 28945 examples [00:13, 2091.91 examples/s]\u001b[A\n",
      "Generating train examples...: 29163 examples [00:13, 2111.87 examples/s]\u001b[A\n",
      "Generating train examples...: 29375 examples [00:13, 2108.01 examples/s]\u001b[A\n",
      "Generating train examples...: 29586 examples [00:14, 2096.11 examples/s]\u001b[A\n",
      "Generating train examples...: 29796 examples [00:14, 2091.05 examples/s]\u001b[A\n",
      "Generating train examples...: 30006 examples [00:14, 2093.71 examples/s]\u001b[A\n",
      "Generating train examples...: 30216 examples [00:14, 2089.36 examples/s]\u001b[A\n",
      "Generating train examples...: 30431 examples [00:14, 2101.18 examples/s]\u001b[A\n",
      "Generating train examples...: 30642 examples [00:14, 2097.55 examples/s]\u001b[A\n",
      "Generating train examples...: 30852 examples [00:14, 2098.28 examples/s]\u001b[A\n",
      "Generating train examples...: 31062 examples [00:14, 2092.54 examples/s]\u001b[A\n",
      "Generating train examples...: 31272 examples [00:14, 2051.91 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 31481 examples [00:14, 2063.13 examples/s]\u001b[A\n",
      "Generating train examples...: 31690 examples [00:15, 2064.97 examples/s]\u001b[A\n",
      "Generating train examples...: 31906 examples [00:15, 2086.98 examples/s]\u001b[A\n",
      "Generating train examples...: 32123 examples [00:15, 2105.37 examples/s]\u001b[A\n",
      "Generating train examples...: 32334 examples [00:15, 2100.51 examples/s]\u001b[A\n",
      "Generating train examples...: 32545 examples [00:15, 2097.10 examples/s]\u001b[A\n",
      "Generating train examples...: 32755 examples [00:15, 2097.96 examples/s]\u001b[A\n",
      "Generating train examples...: 32966 examples [00:15, 2095.30 examples/s]\u001b[A\n",
      "Generating train examples...: 33178 examples [00:15, 2096.42 examples/s]\u001b[A\n",
      "Generating train examples...: 33388 examples [00:15, 2097.48 examples/s]\u001b[A\n",
      "Generating train examples...: 33605 examples [00:15, 2112.83 examples/s]\u001b[A\n",
      "Generating train examples...: 33817 examples [00:16, 2108.68 examples/s]\u001b[A\n",
      "Generating train examples...: 34028 examples [00:16, 2102.80 examples/s]\u001b[A\n",
      "Generating train examples...: 34239 examples [00:16, 2098.69 examples/s]\u001b[A\n",
      "Generating train examples...: 34455 examples [00:16, 2110.68 examples/s]\u001b[A\n",
      "Generating train examples...: 34671 examples [00:16, 2125.38 examples/s]\u001b[A\n",
      "Generating train examples...: 34884 examples [00:16, 2107.87 examples/s]\u001b[A\n",
      "Generating train examples...: 35095 examples [00:16, 2096.04 examples/s]\u001b[A\n",
      "Generating train examples...: 35310 examples [00:16, 2105.81 examples/s]\u001b[A\n",
      "Generating train examples...: 35521 examples [00:16, 2100.82 examples/s]\u001b[A\n",
      "Generating train examples...: 35732 examples [00:16, 2091.10 examples/s]\u001b[A\n",
      "Generating train examples...: 35945 examples [00:17, 2096.44 examples/s]\u001b[A\n",
      "Generating train examples...: 36155 examples [00:17, 2097.50 examples/s]\u001b[A\n",
      "Generating train examples...: 36365 examples [00:17, 2079.64 examples/s]\u001b[A\n",
      "Generating train examples...: 36579 examples [00:17, 2091.35 examples/s]\u001b[A\n",
      "Generating train examples...: 36789 examples [00:17, 2075.41 examples/s]\u001b[A\n",
      "Generating train examples...: 36997 examples [00:17, 2070.63 examples/s]\u001b[A\n",
      "Generating train examples...: 37208 examples [00:17, 2082.31 examples/s]\u001b[A\n",
      "Generating train examples...: 37421 examples [00:17, 2090.28 examples/s]\u001b[A\n",
      "Generating train examples...: 37632 examples [00:17, 2096.14 examples/s]\u001b[A\n",
      "Generating train examples...: 37844 examples [00:17, 2097.03 examples/s]\u001b[A\n",
      "Generating train examples...: 38054 examples [00:18, 2085.46 examples/s]\u001b[A\n",
      "Generating train examples...: 38269 examples [00:18, 2098.42 examples/s]\u001b[A\n",
      "Generating train examples...: 38483 examples [00:18, 2110.79 examples/s]\u001b[A\n",
      "Generating train examples...: 38695 examples [00:18, 2113.54 examples/s]\u001b[A\n",
      "Generating train examples...: 38907 examples [00:18, 2109.17 examples/s]\u001b[A\n",
      "Generating train examples...: 39118 examples [00:18, 2103.14 examples/s]\u001b[A\n",
      "Generating train examples...: 39331 examples [00:18, 2104.87 examples/s]\u001b[A\n",
      "Generating train examples...: 39543 examples [00:18, 2109.38 examples/s]\u001b[A\n",
      "Generating train examples...: 39754 examples [00:18, 2109.56 examples/s]\u001b[A\n",
      "Generating train examples...: 39971 examples [00:18, 2121.33 examples/s]\u001b[A\n",
      "Generating train examples...: 40184 examples [00:19, 2123.90 examples/s]\u001b[A\n",
      "Generating train examples...: 40398 examples [00:19, 2122.36 examples/s]\u001b[A\n",
      "Generating train examples...: 40611 examples [00:19, 2118.32 examples/s]\u001b[A\n",
      "Generating train examples...: 40823 examples [00:19, 2112.51 examples/s]\u001b[A\n",
      "Generating train examples...: 41038 examples [00:19, 2123.69 examples/s]\u001b[A\n",
      "Generating train examples...: 41251 examples [00:19, 2069.91 examples/s]\u001b[A\n",
      "Generating train examples...: 41463 examples [00:19, 2078.52 examples/s]\u001b[A\n",
      "Generating train examples...: 41677 examples [00:19, 2090.48 examples/s]\u001b[A\n",
      "Generating train examples...: 41891 examples [00:19, 2098.92 examples/s]\u001b[A\n",
      "Generating train examples...: 42106 examples [00:19, 2107.81 examples/s]\u001b[A\n",
      "Generating train examples...: 42319 examples [00:20, 2108.14 examples/s]\u001b[A\n",
      "Generating train examples...: 42536 examples [00:20, 2120.25 examples/s]\u001b[A\n",
      "Generating train examples...: 42749 examples [00:20, 2110.57 examples/s]\u001b[A\n",
      "Generating train examples...: 42965 examples [00:20, 2118.98 examples/s]\u001b[A\n",
      "Generating train examples...: 43182 examples [00:20, 2127.82 examples/s]\u001b[A\n",
      "Generating train examples...: 43395 examples [00:20, 2122.14 examples/s]\u001b[A\n",
      "Generating train examples...: 43608 examples [00:20, 2118.17 examples/s]\u001b[A\n",
      "Generating train examples...: 43821 examples [00:20, 2115.40 examples/s]\u001b[A\n",
      "Generating train examples...: 44033 examples [00:20, 2110.48 examples/s]\u001b[A\n",
      "Generating train examples...: 44245 examples [00:21, 2107.04 examples/s]\u001b[A\n",
      "Generating train examples...: 44458 examples [00:21, 2107.60 examples/s]\u001b[A\n",
      "Generating train examples...: 44671 examples [00:21, 2108.01 examples/s]\u001b[A\n",
      "Generating train examples...: 44884 examples [00:21, 2114.55 examples/s]\u001b[A\n",
      "Generating train examples...: 45102 examples [00:21, 2127.74 examples/s]\u001b[A\n",
      "Generating train examples...: 45315 examples [00:21, 2122.07 examples/s]\u001b[A\n",
      "Generating train examples...: 45528 examples [00:21, 2118.12 examples/s]\u001b[A\n",
      "Generating train examples...: 45740 examples [00:21, 2112.38 examples/s]\u001b[A\n",
      "Generating train examples...: 45952 examples [00:21, 2114.65 examples/s]\u001b[A\n",
      "Generating train examples...: 46164 examples [00:21, 2116.25 examples/s]\u001b[A\n",
      "Generating train examples...: 46376 examples [00:22, 2111.06 examples/s]\u001b[A\n",
      "Generating train examples...: 46588 examples [00:22, 2107.44 examples/s]\u001b[A\n",
      "Generating train examples...: 46802 examples [00:22, 2110.88 examples/s]\u001b[A\n",
      "Generating train examples...: 47017 examples [00:22, 2122.54 examples/s]\u001b[A\n",
      "Generating train examples...: 47230 examples [00:22, 2112.14 examples/s]\u001b[A\n",
      "Generating train examples...: 47447 examples [00:22, 2123.06 examples/s]\u001b[A\n",
      "Generating train examples...: 47664 examples [00:22, 2130.70 examples/s]\u001b[A\n",
      "Generating train examples...: 47878 examples [00:22, 2120.82 examples/s]\u001b[A\n",
      "Generating train examples...: 48091 examples [00:22, 2111.00 examples/s]\u001b[A\n",
      "Generating train examples...: 48307 examples [00:22, 2119.27 examples/s]\u001b[A\n",
      "Generating train examples...: 48521 examples [00:23, 2125.43 examples/s]\u001b[A\n",
      "Generating train examples...: 48738 examples [00:23, 2132.36 examples/s]\u001b[A\n",
      "Generating train examples...: 48952 examples [00:23, 2134.63 examples/s]\u001b[A\n",
      "Generating train examples...: 49169 examples [00:23, 2138.81 examples/s]\u001b[A\n",
      "Generating train examples...: 49383 examples [00:23, 2139.16 examples/s]\u001b[A\n",
      "Generating train examples...: 49598 examples [00:23, 2136.02 examples/s]\u001b[A\n",
      "Generating train examples...: 49813 examples [00:23, 2140.19 examples/s]\u001b[A\n",
      "Generating train examples...: 50029 examples [00:23, 2146.11 examples/s]\u001b[A\n",
      "Generating train examples...: 50247 examples [00:23, 2149.82 examples/s]\u001b[A\n",
      "Generating train examples...: 50464 examples [00:23, 2149.43 examples/s]\u001b[A\n",
      "Generating train examples...: 50682 examples [00:24, 2152.14 examples/s]\u001b[A\n",
      "Generating train examples...: 50898 examples [00:24, 2148.07 examples/s]\u001b[A\n",
      "Generating train examples...: 51115 examples [00:24, 2148.20 examples/s]\u001b[A\n",
      "Generating train examples...: 51333 examples [00:24, 2151.27 examples/s]\u001b[A\n",
      "Generating train examples...: 51549 examples [00:24, 2147.47 examples/s]\u001b[A\n",
      "Generating train examples...: 51765 examples [00:24, 2144.81 examples/s]\u001b[A\n",
      "Generating train examples...: 51984 examples [00:24, 2151.87 examples/s]\u001b[A\n",
      "Generating train examples...: 52200 examples [00:24, 2135.19 examples/s]\u001b[A\n",
      "Generating train examples...: 52414 examples [00:24, 2081.06 examples/s]\u001b[A\n",
      "Generating train examples...: 52628 examples [00:24, 2098.28 examples/s]\u001b[A\n",
      "Generating train examples...: 52843 examples [00:25, 2113.51 examples/s]\u001b[A\n",
      "Generating train examples...: 53061 examples [00:25, 2126.90 examples/s]\u001b[A\n",
      "Generating train examples...: 53278 examples [00:25, 2133.36 examples/s]\u001b[A\n",
      "Generating train examples...: 53492 examples [00:25, 2122.71 examples/s]\u001b[A\n",
      "Generating train examples...: 53709 examples [00:25, 2130.42 examples/s]\u001b[A\n",
      "Generating train examples...: 53924 examples [00:25, 2129.92 examples/s]\u001b[A\n",
      "Generating train examples...: 54140 examples [00:25, 2138.86 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 54357 examples [00:25, 2141.76 examples/s]\u001b[A\n",
      "Generating train examples...: 54573 examples [00:25, 2147.20 examples/s]\u001b[A\n",
      "Generating train examples...: 54788 examples [00:25, 2148.02 examples/s]\u001b[A\n",
      "Generating train examples...: 55005 examples [00:26, 2148.18 examples/s]\u001b[A\n",
      "Generating train examples...: 55221 examples [00:26, 2145.31 examples/s]\u001b[A\n",
      "Generating train examples...: 55436 examples [00:26, 2146.70 examples/s]\u001b[A\n",
      "Generating train examples...: 55653 examples [00:26, 2147.25 examples/s]\u001b[A\n",
      "Generating train examples...: 55868 examples [00:26, 2128.99 examples/s]\u001b[A\n",
      "Generating train examples...: 56082 examples [00:26, 2125.95 examples/s]\u001b[A\n",
      "Generating train examples...: 56298 examples [00:26, 2136.08 examples/s]\u001b[A\n",
      "Generating train examples...: 56516 examples [00:26, 2142.79 examples/s]\u001b[A\n",
      "Generating train examples...: 56731 examples [00:26, 2144.93 examples/s]\u001b[A\n",
      "Generating train examples...: 56948 examples [00:26, 2146.01 examples/s]\u001b[A\n",
      "Generating train examples...: 57166 examples [00:27, 2149.74 examples/s]\u001b[A\n",
      "Generating train examples...: 57381 examples [00:27, 2149.82 examples/s]\u001b[A\n",
      "Generating train examples...: 57596 examples [00:27, 2149.87 examples/s]\u001b[A\n",
      "Generating train examples...: 57812 examples [00:27, 2146.48 examples/s]\u001b[A\n",
      "Generating train examples...: 58030 examples [00:27, 2150.08 examples/s]\u001b[A\n",
      "Generating train examples...: 58246 examples [00:27, 2146.62 examples/s]\u001b[A\n",
      "Generating train examples...: 58464 examples [00:27, 2150.17 examples/s]\u001b[A\n",
      "Generating train examples...: 58681 examples [00:27, 2149.67 examples/s]\u001b[A\n",
      "Generating train examples...: 58899 examples [00:27, 2152.30 examples/s]\u001b[A\n",
      "Generating train examples...: 59117 examples [00:27, 2154.13 examples/s]\u001b[A\n",
      "Generating train examples...: 59333 examples [00:28, 2149.48 examples/s]\u001b[A\n",
      "Generating train examples...: 59548 examples [00:28, 2143.25 examples/s]\u001b[A\n",
      "Generating train examples...: 59763 examples [00:28, 2138.87 examples/s]\u001b[A\n",
      "Generating train examples...: 59978 examples [00:28, 2135.84 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-train.tfrecord*...:   0%|          | 0/60000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-train.tfrecord*...:  15%|█▍        | 8970/60000 [00:00<00:00, 89699.87 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-train.tfrecord*...:  36%|███▌      | 21338/60000 [00:00<00:00, 109047.59 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-train.tfrecord*...:  56%|█████▌    | 33418/60000 [00:00<00:00, 114396.71 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-train.tfrecord*...:  76%|███████▌  | 45682/60000 [00:00<00:00, 117183.02 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-train.tfrecord*...:  97%|█████████▋| 57976/60000 [00:00<00:00, 118824.54 examples/s]\u001b[A\n",
      "Generating splits...:  50%|█████     | 1/2 [00:28<00:28, 28.96s/ splits]                                                                                           \u001b[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 180 examples [00:00, 1782.19 examples/s]\u001b[A\n",
      "Generating test examples...: 397 examples [00:00, 1997.65 examples/s]\u001b[A\n",
      "Generating test examples...: 613 examples [00:00, 2062.04 examples/s]\u001b[A\n",
      "Generating test examples...: 831 examples [00:00, 2100.09 examples/s]\u001b[A\n",
      "Generating test examples...: 1047 examples [00:00, 2121.56 examples/s]\u001b[A\n",
      "Generating test examples...: 1265 examples [00:00, 2134.12 examples/s]\u001b[A\n",
      "Generating test examples...: 1479 examples [00:00, 2136.01 examples/s]\u001b[A\n",
      "Generating test examples...: 1696 examples [00:00, 2140.02 examples/s]\u001b[A\n",
      "Generating test examples...: 1914 examples [00:00, 2145.78 examples/s]\u001b[A\n",
      "Generating test examples...: 2132 examples [00:01, 2149.69 examples/s]\u001b[A\n",
      "Generating test examples...: 2347 examples [00:01, 2136.76 examples/s]\u001b[A\n",
      "Generating test examples...: 2564 examples [00:01, 2140.36 examples/s]\u001b[A\n",
      "Generating test examples...: 2779 examples [00:01, 2143.25 examples/s]\u001b[A\n",
      "Generating test examples...: 2994 examples [00:01, 2145.28 examples/s]\u001b[A\n",
      "Generating test examples...: 3212 examples [00:01, 2149.25 examples/s]\u001b[A\n",
      "Generating test examples...: 3427 examples [00:01, 2149.47 examples/s]\u001b[A\n",
      "Generating test examples...: 3644 examples [00:01, 2149.19 examples/s]\u001b[A\n",
      "Generating test examples...: 3860 examples [00:01, 2146.00 examples/s]\u001b[A\n",
      "Generating test examples...: 4078 examples [00:01, 2149.74 examples/s]\u001b[A\n",
      "Generating test examples...: 4296 examples [00:02, 2152.35 examples/s]\u001b[A\n",
      "Generating test examples...: 4515 examples [00:02, 2157.14 examples/s]\u001b[A\n",
      "Generating test examples...: 4732 examples [00:02, 2154.54 examples/s]\u001b[A\n",
      "Generating test examples...: 4950 examples [00:02, 2155.71 examples/s]\u001b[A\n",
      "Generating test examples...: 5169 examples [00:02, 2159.50 examples/s]\u001b[A\n",
      "Generating test examples...: 5385 examples [00:02, 2153.22 examples/s]\u001b[A\n",
      "Generating test examples...: 5601 examples [00:02, 2142.47 examples/s]\u001b[A\n",
      "Generating test examples...: 5816 examples [00:02, 2125.75 examples/s]\u001b[A\n",
      "Generating test examples...: 6029 examples [00:02, 2114.48 examples/s]\u001b[A\n",
      "Generating test examples...: 6241 examples [00:02, 2103.66 examples/s]\u001b[A\n",
      "Generating test examples...: 6452 examples [00:03, 2093.14 examples/s]\u001b[A\n",
      "Generating test examples...: 6667 examples [00:03, 2103.75 examples/s]\u001b[A\n",
      "Generating test examples...: 6878 examples [00:03, 2099.37 examples/s]\u001b[A\n",
      "Generating test examples...: 7088 examples [00:03, 2099.56 examples/s]\u001b[A\n",
      "Generating test examples...: 7299 examples [00:03, 2096.42 examples/s]\u001b[A\n",
      "Generating test examples...: 7509 examples [00:03, 2085.07 examples/s]\u001b[A\n",
      "Generating test examples...: 7718 examples [00:03, 2080.35 examples/s]\u001b[A\n",
      "Generating test examples...: 7929 examples [00:03, 2089.16 examples/s]\u001b[A\n",
      "Generating test examples...: 8138 examples [00:03, 2083.21 examples/s]\u001b[A\n",
      "Generating test examples...: 8349 examples [00:03, 2084.99 examples/s]\u001b[A\n",
      "Generating test examples...: 8561 examples [00:04, 2095.41 examples/s]\u001b[A\n",
      "Generating test examples...: 8775 examples [00:04, 2102.45 examples/s]\u001b[A\n",
      "Generating test examples...: 8986 examples [00:04, 2104.70 examples/s]\u001b[A\n",
      "Generating test examples...: 9198 examples [00:04, 2103.00 examples/s]\u001b[A\n",
      "Generating test examples...: 9409 examples [00:04, 2098.81 examples/s]\u001b[A\n",
      "Generating test examples...: 9619 examples [00:04, 2062.25 examples/s]\u001b[A\n",
      "Generating test examples...: 9834 examples [00:04, 2082.01 examples/s]\u001b[A\n",
      "                                                                      \u001b[A\n",
      "Shuffling C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1.incompleteDWDIWP\\mnist-test.tfrecord*...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                                                                                                                  \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\Mark\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the data, shuffle and split into test and train\n",
    "mnist_data, mnist_info = tfds.load('mnist', with_info=True, shuffle_files=True, as_supervised=True, split=['train', 'test'])\n",
    "\n",
    "# Convert the samples from integers to floating-point numbers\n",
    "def normalize_img(image, label):\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Build your input pipelines\n",
    "mnist_train = mnist_data[0].map(normalize_img).batch(128)\n",
    "mnist_test = mnist_data[1].map(normalize_img).batch(128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c61dec",
   "metadata": {},
   "source": [
    "The sixth cell is a Markdown cell with the text \"Let's take a look at how the data is organized:\". This implies that the next cells will delve into the structure of the MNIST dataset, helping you understand its layout and format. Understanding the data structure is crucial before proceeding with any analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "print('Training image data: {0}'.format(mnist.train.images.shape))\n",
    "print('Validation image data: {0}'.format(mnist.validation.images.shape))\n",
    "print('Testing image data: {0}'.format(mnist.test.images.shape))\n",
    "print('28 x 28 = {0}'.format(28*28))\n",
    "\n",
    "print('\\nTest Labels: {0}'.format(mnist.test.labels.shape))\n",
    "labels = np.arange(10)\n",
    "num_labels = np.sum(mnist.test.labels, axis=0, dtype=np.int)\n",
    "print('Label distribution:{0}'.format(list(zip(labels, num_labels))))\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled one-hot as {0}'.format(mnist.train.labels[1,:]))\n",
    "image = np.reshape(mnist.train.images[1,:],[28,28])\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ffaaa",
   "metadata": {},
   "source": [
    "The first four print statements are displaying the shapes of the training, validation, and testing datasets. The shape of a dataset in this context is the dimensions of the matrix that stores the data. For instance, a shape of (55000, 784) for the training images means there are 55,000 images, each represented as a 1D array of 784 elements (pixels).\n",
    "\n",
    "The next part is looking at the labels. It prints the shape of the test labels array, then creates an array labels of the possible label values (0-9 for MNIST), and calculates num_labels, the number of occurrences of each label in the test dataset. It then prints a list of tuples, each tuple being (label, count), showing the distribution of labels in the test dataset.\n",
    "\n",
    "The final part of the cell is showing an example image from the training set. It prints the one-hot label of the first image in the training set, reshapes the corresponding 1D image data to a 2D 28x28 format, and displays the image using matplotlib.pyplot.imshow.\n",
    "\n",
    "The cell has an error because np (short for numpy) is not defined. This is likely because the cell that imports numpy was not run before this cell.\n",
    "\n",
    "Here's how you could update this code to work properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f38eec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset statistics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining image data: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mmnist_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting image data: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mnist_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Labels: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mnist_info\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_classes))\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Dataset statistics\n",
    "print('Training image data: {0}'.format(mnist_data['train'].shape))\n",
    "print('Testing image data: {0}'.format(mnist_data['test'].shape))\n",
    "\n",
    "print('\\nTest Labels: {0}'.format(mnist_info.features['label'].num_classes))\n",
    "\n",
    "# Label distribution\n",
    "num_labels = np.bincount([label.numpy() for image, label in tfds.as_dataframe(mnist_data['test'], mnist_info).itertuples(index=False)])\n",
    "print('Label distribution:{0}'.format(list(zip(np.arange(10), num_labels))))\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled as {0}'.format(mnist_data['train'].take(1)))\n",
    "image = next(iter(mnist_data['train'].take(1)))[0].numpy()\n",
    "plt.imshow(image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1b2e3",
   "metadata": {},
   "source": [
    "This updated code works with the new way we loaded the MNIST data using tensorflow_datasets. The changes are mainly accessing the data and info using the new variables mnist_data and mnist_info, and using TensorFlow's Dataset API to get the label distribution and to view an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a8bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image data: <PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "Testing image data: <PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "\n",
      "Test Labels: 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Labels: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mnist_info\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_classes))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Label distribution\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount([label\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m image, label \u001b[38;5;129;01min\u001b[39;00m tfds\u001b[38;5;241m.\u001b[39mas_dataframe(mnist_data[\u001b[38;5;241m1\u001b[39m], mnist_info)\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel distribution:\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m), num_labels))))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Example image\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Labels: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mnist_info\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_classes))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Label distribution\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount([\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m image, label \u001b[38;5;129;01min\u001b[39;00m tfds\u001b[38;5;241m.\u001b[39mas_dataframe(mnist_data[\u001b[38;5;241m1\u001b[39m], mnist_info)\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel distribution:\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m), num_labels))))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Example image\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "# Updated code from above\n",
    "# Dataset statistics\n",
    "print('Training image data: {0}'.format(mnist_data[0]))\n",
    "print('Testing image data: {0}'.format(mnist_data[1]))\n",
    "\n",
    "print('\\nTest Labels: {0}'.format(mnist_info.features['label'].num_classes))\n",
    "\n",
    "# Label distribution\n",
    "num_labels = np.bincount([label.numpy() for image, label in tfds.as_dataframe(mnist_data[1], mnist_info).itertuples(index=False)])\n",
    "print('Label distribution:{0}'.format(list(zip(np.arange(10), num_labels))))\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled as {0}'.format(mnist_data[0].take(1)))\n",
    "image = next(iter(mnist_data[0].take(1)))[0].numpy()\n",
    "plt.imshow(image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb05cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image data: <PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "Testing image data: <PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "\n",
      "Test Labels: 10\n",
      "Label distribution:[(0, 980), (1, 1135), (2, 1032), (3, 1010), (4, 982), (5, 892), (6, 958), (7, 1028), (8, 974), (9, 1009)]\n",
      "\n",
      "Train image 1 is labelled as <TakeDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1df4d5c9390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY9UlEQVR4nO3df2hV9/3H8detjbfWXS8ETe69NWZhKCs1E/wxNbQauxkamFRTwSqM+I/T+mOEtJQ5GWb7w4hQ1z+yOiarU1a/dXTWCYqaoYkOlxFDpOKKpBjnHSbLzNy9Mdo46+f7h3jpbVL1XO/NO/fm+YAD3nPPJ+fj6Wmentx7T3zOOScAAAw8ZT0BAMDoRYQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZp60n8FX37t3TtWvXFAgE5PP5rKcDAPDIOae+vj5FIhE99dTDr3VGXISuXbumoqIi62kAAJ5QNBrV5MmTH7rNiPtxXCAQsJ4CACANHuf7ecYi9N5776mkpETPPPOMZs2apTNnzjzWOH4EBwC54XG+n2ckQgcOHFBNTY22bNmi9vZ2vfTSS6qsrNTVq1czsTsAQJbyZeIu2nPnztXMmTO1a9euxLrnn39eS5cuVX19/UPHxuNxBYPBdE8JADDMYrGYJkyY8NBt0n4ldOfOHbW1tamioiJpfUVFhc6ePTto+4GBAcXj8aQFADA6pD1C169f1xdffKHCwsKk9YWFheru7h60fX19vYLBYGLhnXEAMHpk7I0JX31Byjk35ItUmzdvViwWSyzRaDRTUwIAjDBp/5zQxIkTNWbMmEFXPT09PYOujiTJ7/fL7/enexoAgCyQ9iuhsWPHatasWWpsbExa39jYqLKysnTvDgCQxTJyx4Ta2lr98Ic/1OzZszV//nz95je/0dWrV7Vu3bpM7A4AkKUyEqEVK1aot7dXv/jFL9TV1aXp06fr6NGjKi4uzsTuAABZKiOfE3oSfE4IAHKDyeeEAAB4XEQIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZp60nAGDkWb58uecxf/jDHzyPWbt2recxu3fv9jwGIxdXQgAAM0QIAGAm7RGqq6uTz+dLWkKhULp3AwDIARl5TeiFF17Qn//858TjMWPGZGI3AIAsl5EIPf3001z9AAAeKSOvCXV0dCgSiaikpESvv/66Ll++/LXbDgwMKB6PJy0AgNEh7RGaO3eu9u3bp+PHj2v37t3q7u5WWVmZent7h9y+vr5ewWAwsRQVFaV7SgCAESrtEaqsrNRrr72m0tJSff/739eRI0ckSXv37h1y+82bNysWiyWWaDSa7ikBAEaojH9Ydfz48SotLVVHR8eQz/v9fvn9/kxPAwAwAmX8c0IDAwP69NNPFQ6HM70rAECWSXuE3nrrLTU3N6uzs1N/+9vftHz5csXjcVVXV6d7VwCALJf2H8f985//1MqVK3X9+nVNmjRJ8+bNU0tLi4qLi9O9KwBAlkt7hD788MN0f0kAw2zVqlWexzjnPI/Jz8/3PAa5hXvHAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmMv5L7QDYSfXu9ZWVlZ7HtLW1eR6zf/9+z2OQW7gSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBnuoo1h5fP5hmU/zrlh2c9I9+Mf/zilcWPHjvU85vLly57HRKNRz2OQW7gSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcANTDKvy8nLPY375y196HrNu3TrPYySppaUlpXEjVWlp6bDt6/z588O2L+QOroQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADPcwBTD6vbt257HpHITzoULF3oeI43sG5hOnjzZ85hUj0NfX5/nMXv37k1pXxjduBICAJghQgAAM54jdPr0aS1ZskSRSEQ+n0+HDh1Ket45p7q6OkUiEY0bN07l5eW6ePFiuuYLAMghniPU39+vGTNmqKGhYcjnd+zYoZ07d6qhoUGtra0KhUJavHhxSj9jBgDkNs9vTKisrFRlZeWQzznn9O6772rLli2qqqqSdP/FysLCQu3fv19r1659stkCAHJKWl8T6uzsVHd3tyoqKhLr/H6/Fi5cqLNnzw45ZmBgQPF4PGkBAIwOaY1Qd3e3JKmwsDBpfWFhYeK5r6qvr1cwGEwsRUVF6ZwSAGAEy8i743w+X9Jj59ygdQ9s3rxZsVgssUSj0UxMCQAwAqX1w6qhUEjS/SuicDicWN/T0zPo6ugBv98vv9+fzmkAALJEWq+ESkpKFAqF1NjYmFh3584dNTc3q6ysLJ27AgDkAM9XQjdv3tRnn32WeNzZ2anz588rPz9fU6ZMUU1NjbZt26apU6dq6tSp2rZtm5599lmtWrUqrRMHAGQ/zxE6d+6cFi1alHhcW1srSaqurtbvfvc7vf3227p9+7bWr1+vGzduaO7cuTpx4oQCgUD6Zg0AyAmeI1ReXi7n3Nc+7/P5VFdXp7q6uieZF3JUT0+P9RSy1rJlyzyPycvLS2lf586d8zymq6srpX1hdOPecQAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADCT1t+sCjxKfn6+9RSyViQSGbZ9NTU1Ddu+MLpxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGphhWy5Yt8zzG5/NlYCa2nnvuOc9j3njjDc9jUj1277//fkrjAK+4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADU6TM7/d7HvOjH/3I8xjnnOcxK1eu9DxGkr75zW96HpOfn+95zHe+8x3PYwKBgOcx7e3tnsdIUmdnZ0rjAK+4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADU6Rs1apVnsekcrPPVJSWlqY0LpUbi6Zyg9Xhsn379pTG3bt3L80zAYbGlRAAwAwRAgCY8Ryh06dPa8mSJYpEIvL5fDp06FDS86tXr5bP50ta5s2bl675AgByiOcI9ff3a8aMGWpoaPjabV555RV1dXUllqNHjz7RJAEAucnzGxMqKytVWVn50G38fr9CoVDKkwIAjA4ZeU2oqalJBQUFmjZtmtasWaOenp6v3XZgYEDxeDxpAQCMDmmPUGVlpT744AOdPHlS77zzjlpbW/Xyyy9rYGBgyO3r6+sVDAYTS1FRUbqnBAAYodL+OaEVK1Yk/jx9+nTNnj1bxcXFOnLkiKqqqgZtv3nzZtXW1iYex+NxQgQAo0TGP6waDodVXFysjo6OIZ/3+/3y+/2ZngYAYATK+OeEent7FY1GFQ6HM70rAECW8XwldPPmTX322WeJx52dnTp//rzy8/OVn5+vuro6vfbaawqHw7py5Yp++tOfauLEiVq2bFlaJw4AyH6eI3Tu3DktWrQo8fjB6znV1dXatWuXLly4oH379um///2vwuGwFi1apAMHDigQCKRv1gCAnOA5QuXl5Q+9YePx48efaELIHnPmzPE85tatW57HvP/++57HXLt2zfMYSfrPf/7jecz169c9j/noo488j0nFsWPHhmU/QKq4dxwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMZPw3qyJ3rV+/fljGjHTLly/3PMbn83kec/DgQc9j4vG45zHAcOJKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwww1MgSe0atUqz2Occ57HtLa2eh4DjHRcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriBKfCEFi5c6HlMKjcwbW5u9jwGGOm4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADU+BLZs6c6XnM0097/9/oxIkTnse0tLR4HgOMdFwJAQDMECEAgBlPEaqvr9ecOXMUCARUUFCgpUuX6tKlS0nbOOdUV1enSCSicePGqby8XBcvXkzrpAEAucFThJqbm7Vhwwa1tLSosbFRd+/eVUVFhfr7+xPb7NixQzt37lRDQ4NaW1sVCoW0ePFi9fX1pX3yAIDs5ukV1WPHjiU93rNnjwoKCtTW1qYFCxbIOad3331XW7ZsUVVVlSRp7969Kiws1P79+7V27dr0zRwAkPWe6DWhWCwmScrPz5ckdXZ2qru7WxUVFYlt/H6/Fi5cqLNnzw75NQYGBhSPx5MWAMDokHKEnHOqra3Viy++qOnTp0uSuru7JUmFhYVJ2xYWFiae+6r6+noFg8HEUlRUlOqUAABZJuUIbdy4UZ988on+7//+b9BzPp8v6bFzbtC6BzZv3qxYLJZYotFoqlMCAGSZlD6sumnTJh0+fFinT5/W5MmTE+tDoZCk+1dE4XA4sb6np2fQ1dEDfr9ffr8/lWkAALKcpysh55w2btyogwcP6uTJkyopKUl6vqSkRKFQSI2NjYl1d+7cUXNzs8rKytIzYwBAzvB0JbRhwwbt379ff/rTnxQIBBKv8wSDQY0bN04+n081NTXatm2bpk6dqqlTp2rbtm169tlntWrVqoz8BQAA2ctThHbt2iVJKi8vT1q/Z88erV69WpL09ttv6/bt21q/fr1u3LihuXPn6sSJEwoEAmmZMAAgd/icc856El8Wj8cVDAatp4FR6ss/Sn5c3/ve9zyP+d///ud5TE1NjecxD/7hCFiIxWKaMGHCQ7fh3nEAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwk9JvVgVyVSo3lU9lzMWLFz2P+eijjzyPAUY6roQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADPcwBT4kueff97zmP7+fs9jqqqqPI/597//7XkMMNJxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpsCXjBs3zvOYf/3rX57HXLlyxfMYIBdxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpsCXTJw40XoKwKjClRAAwAwRAgCY8RSh+vp6zZkzR4FAQAUFBVq6dKkuXbqUtM3q1avl8/mSlnnz5qV10gCA3OApQs3NzdqwYYNaWlrU2Niou3fvqqKiQv39/UnbvfLKK+rq6kosR48eTeukAQC5wdMbE44dO5b0eM+ePSooKFBbW5sWLFiQWO/3+xUKhdIzQwBAznqi14RisZgkKT8/P2l9U1OTCgoKNG3aNK1Zs0Y9PT1f+zUGBgYUj8eTFgDA6OBzzrlUBjrn9Oqrr+rGjRs6c+ZMYv2BAwf0jW98Q8XFxers7NTPfvYz3b17V21tbfL7/YO+Tl1dnX7+85+n/jcAAIxIsVhMEyZMePhGLkXr1693xcXFLhqNPnS7a9euuby8PPfHP/5xyOc///xzF4vFEks0GnWSWFhYWFiyfInFYo9sSUofVt20aZMOHz6s06dPa/LkyQ/dNhwOq7i4WB0dHUM+7/f7h7xCAgDkPk8Rcs5p06ZN+vjjj9XU1KSSkpJHjunt7VU0GlU4HE55kgCA3OTpjQkbNmzQ73//e+3fv1+BQEDd3d3q7u7W7du3JUk3b97UW2+9pb/+9a+6cuWKmpqatGTJEk2cOFHLli3LyF8AAJDFvLwOpK/5ud+ePXucc87dunXLVVRUuEmTJrm8vDw3ZcoUV11d7a5evfrY+4jFYuY/x2RhYWFhefLlcV4TSvndcZkSj8cVDAatpwEAeEKP8+447h0HADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADAz4iLknLOeAgAgDR7n+/mIi1BfX5/1FAAAafA43899boRdety7d0/Xrl1TIBCQz+dLei4ej6uoqEjRaFQTJkwwmqE9jsN9HIf7OA73cRzuGwnHwTmnvr4+RSIRPfXUw691nh6mOT22p556SpMnT37oNhMmTBjVJ9kDHIf7OA73cRzu4zjcZ30cgsHgY2034n4cBwAYPYgQAMBMVkXI7/dr69at8vv91lMxxXG4j+NwH8fhPo7Dfdl2HEbcGxMAAKNHVl0JAQByCxECAJghQgAAM0QIAGAmqyL03nvvqaSkRM8884xmzZqlM2fOWE9pWNXV1cnn8yUtoVDIeloZd/r0aS1ZskSRSEQ+n0+HDh1Ket45p7q6OkUiEY0bN07l5eW6ePGizWQz6FHHYfXq1YPOj3nz5tlMNkPq6+s1Z84cBQIBFRQUaOnSpbp06VLSNqPhfHic45At50PWROjAgQOqqanRli1b1N7erpdeekmVlZW6evWq9dSG1QsvvKCurq7EcuHCBespZVx/f79mzJihhoaGIZ/fsWOHdu7cqYaGBrW2tioUCmnx4sU5dx/CRx0HSXrllVeSzo+jR48O4wwzr7m5WRs2bFBLS4saGxt19+5dVVRUqL+/P7HNaDgfHuc4SFlyPrgs8d3vftetW7cuad23v/1t95Of/MRoRsNv69atbsaMGdbTMCXJffzxx4nH9+7dc6FQyG3fvj2x7vPPP3fBYND9+te/Npjh8PjqcXDOuerqavfqq6+azMdKT0+Pk+Sam5udc6P3fPjqcXAue86HrLgSunPnjtra2lRRUZG0vqKiQmfPnjWalY2Ojg5FIhGVlJTo9ddf1+XLl62nZKqzs1Pd3d1J54bf79fChQtH3bkhSU1NTSooKNC0adO0Zs0a9fT0WE8po2KxmCQpPz9f0ug9H756HB7IhvMhKyJ0/fp1ffHFFyosLExaX1hYqO7ubqNZDb+5c+dq3759On78uHbv3q3u7m6VlZWpt7fXempmHvz3H+3nhiRVVlbqgw8+0MmTJ/XOO++otbVVL7/8sgYGBqynlhHOOdXW1urFF1/U9OnTJY3O82Go4yBlz/kw4u6i/TBf/dUOzrlB63JZZWVl4s+lpaWaP3++vvWtb2nv3r2qra01nJm90X5uSNKKFSsSf54+fbpmz56t4uJiHTlyRFVVVYYzy4yNGzfqk08+0V/+8pdBz42m8+HrjkO2nA9ZcSU0ceJEjRkzZtC/ZHp6egb9i2c0GT9+vEpLS9XR0WE9FTMP3h3IuTFYOBxWcXFxTp4fmzZt0uHDh3Xq1KmkX/0y2s6HrzsOQxmp50NWRGjs2LGaNWuWGhsbk9Y3NjaqrKzMaFb2BgYG9OmnnyocDltPxUxJSYlCoVDSuXHnzh01NzeP6nNDknp7exWNRnPq/HDOaePGjTp48KBOnjypkpKSpOdHy/nwqOMwlBF7Phi+KcKTDz/80OXl5bnf/va37u9//7urqalx48ePd1euXLGe2rB58803XVNTk7t8+bJraWlxP/jBD1wgEMj5Y9DX1+fa29tde3u7k+R27tzp2tvb3T/+8Q/nnHPbt293wWDQHTx40F24cMGtXLnShcNhF4/HjWeeXg87Dn19fe7NN990Z8+edZ2dne7UqVNu/vz57rnnnsup4/DGG2+4YDDompqaXFdXV2K5detWYpvRcD486jhk0/mQNRFyzrlf/epXrri42I0dO9bNnDkz6e2Io8GKFStcOBx2eXl5LhKJuKqqKnfx4kXraWXcqVOnnKRBS3V1tXPu/ttyt27d6kKhkPP7/W7BggXuwoULtpPOgIcdh1u3brmKigo3adIkl5eX56ZMmeKqq6vd1atXraedVkP9/SW5PXv2JLYZDefDo45DNp0P/CoHAICZrHhNCACQm4gQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM/8P03+Md9ToKHIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updated code from above\n",
    "# Dataset statistics\n",
    "print('Training image data: {0}'.format(mnist_data[0]))\n",
    "print('Testing image data: {0}'.format(mnist_data[1]))\n",
    "\n",
    "print('\\nTest Labels: {0}'.format(mnist_info.features['label'].num_classes))\n",
    "\n",
    "# Label distribution\n",
    "num_labels = np.bincount([label for image, label in tfds.as_dataframe(mnist_data[1], mnist_info).itertuples(index=False)])\n",
    "print('Label distribution:{0}'.format(list(zip(np.arange(10), num_labels))))\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled as {0}'.format(mnist_data[0].take(1)))\n",
    "image = next(iter(mnist_data[0].take(1)))[0].numpy()\n",
    "plt.imshow(image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07192673",
   "metadata": {},
   "source": [
    "Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9975fb",
   "metadata": {},
   "source": [
    "\"Define the graph input: this is where we feed in our training images into the model. Since MNIST digits are pretty small and the model we're using is very simple, we'll feed them in as flat vectors.\"\n",
    "\n",
    "In TensorFlow, computations are represented as graphs. The \"graph input\" is the set of values that are input into this graph. The text indicates that the graph input will be the training images, which are fed into the model during training.\n",
    "\n",
    "Since each image in the MNIST dataset is a 2D array (28x28), and the model being used is simple, the images are reshaped into flat 1D arrays (or \"vectors\") of length 784 (since 28*28=784). This is a common practice for simple models or initial baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abd8f19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define input placeholder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m(tf\u001b[38;5;241m.\u001b[39mfloat32, [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m784\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Define input placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ccb76",
   "metadata": {},
   "source": [
    "In TensorFlow 2.0 and above, the tf.placeholder function has been removed. The preferred way to feed data into your model is to use TensorFlow's tf.data API, which allows you to build complex input pipelines from simple, reusable pieces.\n",
    "\n",
    "Here's an example of how you can define a function to flatten your images and one-hot encode your labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff857a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.reshape(image, [-1])  # This flattens the image\n",
    "    label = tf.one_hot(label, depth=10)  # This one-hot encodes the label\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e27af5",
   "metadata": {},
   "source": [
    "You can then use this function with the map method to apply it to all elements in the training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d01b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.map(preprocess)\n",
    "mnist_test = mnist_test.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a104e1e",
   "metadata": {},
   "source": [
    "Now each image is a flat tensor with 784 elements (28x28), and each label is a one-hot encoded tensor with 10 elements (for 10 classes).\n",
    "\n",
    "This updated approach should work with your current version of TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade5421",
   "metadata": {},
   "source": [
    "The eleventh cell is a Markdown cell that provides an explanation of how the probabilities of each digit are calculated in the logistic regression model. Here's a summary:\n",
    "\n",
    "The text explains that to calculate the predicted probabilities of each digit, the model starts with a linear transformation. For a given digit (let's say 3), it multiplies each value of the input vector (the flattened image) by a corresponding weight, sums them all together, and then adds a bias. This is expressed with the equation:\n",
    "\n",
    "\\[\n",
    "y_3 = \\sum_i w_{i,3} x_i + b_3\n",
    "\\]\n",
    "\n",
    "The resulting value \\(y_3\\) is correlated with how likely the model thinks the input digit was a 3. The higher the value of \\(y_3\\), the more likely the model thinks the input image was a 3.\n",
    "\n",
    "Since the goal is to identify all 10 digits, this is done for each digit, resulting in:\n",
    "\n",
    "\\[\n",
    "\\begin{align*}\n",
    "y_0 &= \\sum_i w_{i,0} x_i + b_0 \\\\\n",
    "&\\vdots \\\\\n",
    "y_9 &= \\sum_i w_{i,9} x_i + b_9\n",
    "\\end{align*}\n",
    "\\]\n",
    "\n",
    "This can be expressed in matrix form as:\n",
    "\n",
    "\\[\n",
    "y = W x + b \n",
    "\\]\n",
    "\n",
    "To put this into the TensorFlow computation graph, the weights and biases need to be defined as TensorFlow Variables.\n",
    "\n",
    "The metaphor here is a little like a voting system. Each pixel in the image gets a vote on what digit they think the image is. The weight is how much that pixel's vote counts, and the bias is like a starting number of votes for each digit. The digit with the most votes (highest resulting \\(y\\) value) is the digit the model predicts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe96978",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m W \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m10\u001b[39m]))\n\u001b[0;32m      3\u001b[0m b \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m10\u001b[39m]))\n\u001b[1;32m----> 4\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mx\u001b[49m, W) \u001b[38;5;241m+\u001b[39m b\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Define linear transformation\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e97dd",
   "metadata": {},
   "source": [
    "The error NameError: name 'x' is not defined is occurring because you're trying to use the variable x which was supposed to be defined using tf.placeholder function, a feature that has been removed from TensorFlow 2.0 and above.\n",
    "\n",
    "With the newer versions of TensorFlow (TF2.x), the preferred way is to use Keras (which is integrated into TensorFlow) to define models. Here's an example of how you can define a simple linear model like the one in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28, 1)),  # Flattens the input\n",
    "    layers.Dense(10)  # Linear transformation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64240e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd6c04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77a73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94819d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4798c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
